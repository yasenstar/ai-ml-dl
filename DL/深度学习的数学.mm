<map version="freeplane 1.12.1">
<!--To view this file, download free mind mapping software Freeplane from https://www.freeplane.org -->
<node TEXT="深度学习的数学" LOCALIZED_STYLE_REF="AutomaticLayout.level.root" FOLDED="false" ID="ID_1090958577" CREATED="1409300609620" MODIFIED="1732756705237"><hook NAME="MapStyle" background="#f5f5dcff">
    <properties show_icon_for_attributes="true" edgeColorConfiguration="#808080ff,#ff0000ff,#0000ffff,#00ff00ff,#ff00ffff,#00ffffff,#7c0000ff,#00007cff,#007c00ff,#7c007cff,#007c7cff,#7c7c00ff" show_tags="UNDER_NODES" show_note_icons="true" associatedTemplateLocation="template:/light_sepia_template.mm" fit_to_viewport="false"/>
    <tags category_separator="::"/>

<map_styles>
<stylenode LOCALIZED_TEXT="styles.root_node" STYLE="oval" UNIFORM_SHAPE="true" VGAP_QUANTITY="24 pt">
<font SIZE="24"/>
<stylenode LOCALIZED_TEXT="styles.predefined" POSITION="bottom_or_right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="default" ID="ID_1558627382" ICON_SIZE="12 pt" FORMAT_AS_HYPERLINK="false" COLOR="#2c2b29" BACKGROUND_COLOR="#eedfcc" STYLE="bubble" SHAPE_HORIZONTAL_MARGIN="8 pt" SHAPE_VERTICAL_MARGIN="5 pt" BORDER_WIDTH_LIKE_EDGE="false" BORDER_WIDTH="1.9 px" BORDER_COLOR_LIKE_EDGE="true" BORDER_COLOR="#f0f0f0" BORDER_DASH_LIKE_EDGE="true" BORDER_DASH="SOLID" VGAP_QUANTITY="3 pt">
<arrowlink SHAPE="CUBIC_CURVE" COLOR="#000000" WIDTH="2" TRANSPARENCY="200" DASH="" FONT_SIZE="9" FONT_FAMILY="SansSerif" DESTINATION="ID_1558627382" STARTINCLINATION="81.75 pt;-8.25 pt;" ENDINCLINATION="81.75 pt;19.5 pt;" STARTARROW="NONE" ENDARROW="DEFAULT"/>
<font NAME="SansSerif" SIZE="9" BOLD="false" STRIKETHROUGH="false" ITALIC="false"/>
<edge STYLE="bezier" COLOR="#2e3440" WIDTH="3" DASH="SOLID"/>
<richcontent TYPE="DETAILS" CONTENT-TYPE="plain/auto"/>
<richcontent TYPE="NOTE" CONTENT-TYPE="plain/auto"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.details" COLOR="#ffffff" BACKGROUND_COLOR="#2e3440">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.tags">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.attributes">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.note" COLOR="#000000" BACKGROUND_COLOR="#f6f9a1" TEXT_ALIGN="LEFT">
<icon BUILTIN="clock2"/>
<font SIZE="10" ITALIC="true"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.floating">
<edge STYLE="hide_edge"/>
<cloud COLOR="#f0f0f0" SHAPE="ROUND_RECT"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.selection" COLOR="#2c2b29" BACKGROUND_COLOR="#ffffff" BORDER_COLOR_LIKE_EDGE="false" BORDER_COLOR="#bf616a"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.user-defined" POSITION="bottom_or_right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="styles.important" ID="ID_411331447" COLOR="#ffffff" BACKGROUND_COLOR="#bf616a" BORDER_COLOR="#bf616a">
<icon BUILTIN="yes"/>
<arrowlink COLOR="#bf616a" TRANSPARENCY="255" DESTINATION="ID_411331447"/>
<font NAME="Ubuntu" SIZE="12" BOLD="true"/>
<edge COLOR="#bf616a"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.flower" COLOR="#ffffff" BACKGROUND_COLOR="#255aba" STYLE="oval" TEXT_ALIGN="CENTER" BORDER_WIDTH_LIKE_EDGE="false" BORDER_WIDTH="22 pt" BORDER_COLOR_LIKE_EDGE="false" BORDER_COLOR="#f9d71c" BORDER_DASH_LIKE_EDGE="false" BORDER_DASH="CLOSE_DOTS" MAX_WIDTH="6 cm" MIN_WIDTH="3 cm"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.AutomaticLayout" POSITION="bottom_or_right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="AutomaticLayout.level.root" COLOR="#ffffff" BACKGROUND_COLOR="#2c2b29" STYLE="bubble" SHAPE_HORIZONTAL_MARGIN="10 pt" SHAPE_VERTICAL_MARGIN="10 pt" BORDER_COLOR_LIKE_EDGE="false" BORDER_COLOR="#2c2b29" BORDER_DASH_LIKE_EDGE="true">
<font SIZE="18"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,1" STYLE="bubble" SHAPE_HORIZONTAL_MARGIN="8 pt" SHAPE_VERTICAL_MARGIN="5 pt" BORDER_COLOR="#2c2b29">
<font SIZE="16"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,2" STYLE="bubble" SHAPE_HORIZONTAL_MARGIN="8 pt" SHAPE_VERTICAL_MARGIN="5 pt" BORDER_COLOR_LIKE_EDGE="true" BORDER_COLOR="#f0f0f0">
<font SIZE="14"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,3" STYLE="bubble" SHAPE_HORIZONTAL_MARGIN="8 pt" SHAPE_VERTICAL_MARGIN="5 pt" BORDER_COLOR_LIKE_EDGE="true" BORDER_COLOR="#f0f0f0">
<font SIZE="12"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,4" BACKGROUND_COLOR="#eedfcc" BORDER_COLOR_LIKE_EDGE="true" BORDER_COLOR="#f0f0f0">
<font SIZE="11"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,5" BORDER_COLOR_LIKE_EDGE="true" BORDER_COLOR="#f0f0f0">
<font SIZE="11"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,6" BORDER_COLOR_LIKE_EDGE="true" BORDER_COLOR="#f0f0f0">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,7" BORDER_COLOR="#f0f0f0">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,8" BORDER_COLOR="#f0f0f0">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,9" BORDER_COLOR="#f0f0f0">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,10" BORDER_COLOR="#f0f0f0"/>
</stylenode>
</stylenode>
</map_styles>
</hook>
<hook NAME="accessories/plugins/AutomaticLayout.properties" VALUE="ALL"/>
<font BOLD="true"/>
<hook URI="img/Math-of-DL.png" SIZE="1.0" NAME="ExternalObject"/>
<node TEXT="1. 神经网络NN的思想" FOLDED="true" POSITION="bottom_or_right" ID="ID_1760241156" CREATED="1732756733610" MODIFIED="1732772746625">
<node TEXT="1.1 神经网络neural network和深度学习" ID="ID_1224833060" CREATED="1732756794560" MODIFIED="1732772821101">
<node TEXT="用神经网络实现的人工智能能够自己学习过去的数据" ID="ID_725416796" CREATED="1732772874902" MODIFIED="1732772891671"/>
</node>
<node TEXT="1.2 神经元neuron工作的数学表示" ID="ID_1842142706" CREATED="1732756799725" MODIFIED="1732772813774"/>
<node TEXT="1.3 激活函数：将神经元的工作一般化" ID="ID_791252549" CREATED="1732756815033" MODIFIED="1732756828188">
<node TEXT="抽象化的神经元neuron成为神经单元unit" ID="ID_329485393" CREATED="1732774050545" MODIFIED="1732774080353"/>
<node TEXT="点火：y = u(w1x1+w2x2+w3x3-θ), u称为单位阶跃函数 --&gt; 激活函数，著名的是Sigmoid函数" ID="ID_1668816832" CREATED="1732774141652" MODIFIED="1732778101363"/>
</node>
<node TEXT="1.4 什么是神经网络" ID="ID_1079737042" CREATED="1732772654053" MODIFIED="1732772659904">
<node TEXT="将y=a(z)这样的神经单元连接成网络状，就形成了神经网络" ID="ID_1040331295" CREATED="1732775324685" MODIFIED="1732775362487"/>
<node TEXT="主要考察作为基础的阶层型神经网络和尤其发展而来的卷积神经网络" ID="ID_707181366" CREATED="1732775374473" MODIFIED="1732775412602">
<node TEXT="全连接层：前一层的神经单元与下一层的所有神经单元都有箭头连接" ID="ID_1961034474" CREATED="1732775776322" MODIFIED="1732775814646"/>
<node TEXT="隐藏层：负责特征提取(feature extraction)" ID="ID_1399523843" CREATED="1732775972135" MODIFIED="1732775997000"/>
</node>
<node TEXT="深度学习是叠加了很多层的神经网络，其中著名的就是卷积神经网络" ID="ID_149537995" CREATED="1732775661788" MODIFIED="1732775698770"/>
</node>
<node TEXT="1.5 用恶魔来讲解神经网络的结构" ID="ID_1000423376" CREATED="1732772660061" MODIFIED="1732772671773"/>
<node TEXT="1.6 将恶魔的工作翻译为神经网络的语言" ID="ID_1541521479" CREATED="1732772671960" MODIFIED="1732772684858"/>
<node TEXT="1.7 网络自学习的神经网络" FOLDED="true" ID="ID_1961352918" CREATED="1732772685399" MODIFIED="1732772697403">
<node TEXT="神经网络的参数确定方法分为有监督学习和无监督学习" ID="ID_971292622" CREATED="1732777349966" MODIFIED="1732777370678"/>
<node TEXT="有监督学习指为了确定神经网络的权重和偏置，事先给予数据，这些数据称为学习数据" ID="ID_94094668" CREATED="1732777370930" MODIFIED="1732777417065"/>
<node TEXT="根据给定的的学习数据确定权重和偏置，称为学习" ID="ID_1454487330" CREATED="1732777417286" MODIFIED="1732777439601"/>
<node TEXT="神经网络的学习-模型的最优化：计算神经网络得出的预测值与正解的误差，确定使得误差总和达到最小的权重和偏置" ID="ID_1162342925" CREATED="1732777447353" MODIFIED="1732777503353">
<node TEXT="代价函数(Cost Function)：针对全部学习数据，计算预测值与正解的误差的平方（称平方误差），然后再相加，这个误差的总和" ID="ID_600576398" CREATED="1732777549224" MODIFIED="1732777618810"/>
<node ID="ID_172818614" CREATED="1732777623843" MODIFIED="1732777664731"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      利用平方误差确定参数的方法在数学上称为<span style="font-weight: bold;">最小二乘法</span>
    </p>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="奇点(singularity)：表示人工智能超过人类智能的时间点" ID="ID_1437564208" CREATED="1732777691088" MODIFIED="1732777728160"/>
</node>
</node>
<node TEXT="2. 神经网络的数学基础" FOLDED="true" POSITION="bottom_or_right" ID="ID_1637092293" CREATED="1732756741031" MODIFIED="1732756749574">
<node TEXT="2.1 神经网络所需的函数" FOLDED="true" ID="ID_826248301" CREATED="1732777838343" MODIFIED="1732777847768">
<node TEXT="一次函数 y=ax+b" ID="ID_431322279" CREATED="1732778242230" MODIFIED="1732778272126"/>
<node TEXT="二次函数" ID="ID_1589644140" CREATED="1732780728220" MODIFIED="1732780736919"/>
<node TEXT="单位阶跃函数" ID="ID_1599042940" CREATED="1732780858310" MODIFIED="1732780866599"/>
<node TEXT="指数函数和Sinmoid函数" ID="ID_1368025227" CREATED="1732780889776" MODIFIED="1732780899458"/>
<node TEXT="正态分布的概率密度函数" ID="ID_346402935" CREATED="1732780990820" MODIFIED="1732781001029"/>
</node>
<node TEXT="2.2 有助于理解神经网络的数列和递推关系式" FOLDED="true" ID="ID_1326898758" CREATED="1732777916854" MODIFIED="1732777938704">
<node TEXT="数列的通项公式" ID="ID_1725547676" CREATED="1732781351550" MODIFIED="1732781683593">
<node TEXT="将数列的第n项用一个关于n的式子表示出来，这个式子就是通项公式" ID="ID_527873545" CREATED="1732781683596" MODIFIED="1732781685826"/>
</node>
<node TEXT="数列与递推关系式" ID="ID_1531493386" CREATED="1732781330203" MODIFIED="1732781537197">
<node TEXT="已知首项a1以及相邻两项An, An+1的关系式，就可以确定这个数列，这个关系式就是递推关系式" ID="ID_449695963" CREATED="1732781517202" MODIFIED="1732781608610"/>
</node>
<node TEXT="联立递推关系式" ID="ID_238594557" CREATED="1732781668569" MODIFIED="1732781675858">
<node TEXT="将多个数列的递推关系式联合起来组成一组" ID="ID_799826306" CREATED="1732781732053" MODIFIED="1732781749304"/>
</node>
</node>
<node TEXT="2.3 神经网络中经常用到的Σ符号" FOLDED="true" ID="ID_910268228" CREATED="1732777938871" MODIFIED="1732778069336">
<node TEXT="Σ符号具有线性性质" ID="ID_1696799610" CREATED="1732782027888" MODIFIED="1732782046806"/>
</node>
<node TEXT="2.4 有助于理解神经网络的向量基础" FOLDED="true" ID="ID_1338383886" CREATED="1732778107611" MODIFIED="1732778120842">
<node TEXT="向量的定义：具有大小和方向的量，用箭头表示" ID="ID_1704496615" CREATED="1732782341513" MODIFIED="1732782390637"/>
<node TEXT="向量的大小：表示向量的箭头的长度" ID="ID_481882661" CREATED="1732782843126" MODIFIED="1732782854707"/>
<node TEXT="向量的内积：a*b = |a|*|b|*cosθ" ID="ID_1927101746" CREATED="1732782888666" MODIFIED="1732782928523">
<node TEXT="表示两个向量在多大程度上指向相同方向" ID="ID_196869562" CREATED="1732809651160" MODIFIED="1732809672985"/>
</node>
<node TEXT="柯西-施瓦茨不等式" ID="ID_1759074536" CREATED="1732809160993" MODIFIED="1732809179529">
<node TEXT="-|a||b|&lt;=a*b&gt;=|a||b|" ID="ID_1394089711" CREATED="1732809554842" MODIFIED="1732809571223"/>
</node>
<node TEXT="内积的坐标表示" ID="ID_1055927725" CREATED="1732809785765" MODIFIED="1732809794422">
<node TEXT="a=(a1,a2), b=(b1,b2), then a*b = a1b1+a2b2" ID="ID_332130971" CREATED="1732809794432" MODIFIED="1732809824336"/>
<node TEXT="a=(a1,a2,a3), b=(b1,b2,b3), then a*b = a1b1+a2b2+a3b3" ID="ID_1910176072" CREATED="1732809794432" MODIFIED="1732809843218"/>
</node>
<node TEXT="向量的一般化" ID="ID_1052712530" CREATED="1732809847759" MODIFIED="1732809852346"/>
<node TEXT="张量tensor" ID="ID_1933380535" CREATED="1732809900767" MODIFIED="1732809911549">
<node TEXT="向量概念的推广" ID="ID_1788959540" CREATED="1732809913678" MODIFIED="1732809923875"/>
</node>
</node>
<node TEXT="2.5 有助于理解神经网络的矩阵基础" FOLDED="true" ID="ID_1433482384" CREATED="1732778121004" MODIFIED="1732778129619">
<node TEXT="矩阵的乘法不满足交换律" ID="ID_1931731919" CREATED="1732847686893" MODIFIED="1732847699818"/>
<node TEXT="Hadamard乘积：相同形状的矩阵A,B，将相同位置的元素相乘产生的矩阵" ID="ID_572172979" CREATED="1732847778270" MODIFIED="1732847820403"/>
<node TEXT="转置矩阵Transposed Matrix：将矩阵A的第i行第j列的元素与第j行第i列的元素交换产生的矩阵" ID="ID_1312068252" CREATED="1732847826451" MODIFIED="1732847879876"/>
</node>
<node TEXT="2.6 神经网络的导数基础" FOLDED="true" ID="ID_1113788616" CREATED="1732778129779" MODIFIED="1732778138154">
<node TEXT="已知函数f(x)，求导函数f&apos;(x)，称为对函数f(x)求导，当导数的值存在时，称函数可导" ID="ID_1104585907" CREATED="1732848528851" MODIFIED="1732848573131"/>
<node TEXT="在平面直角坐标系中，f&apos;(x)表示曲线的某点的切线的斜率" ID="ID_678196017" CREATED="1732848900329" MODIFIED="1732848932629"/>
<node TEXT="导数的线性性（和的导数为导数的和，常数倍的导数是导数的常数倍），是后面的误差反向传播法背后的主角" ID="ID_814623914" CREATED="1732849781474" MODIFIED="1732849910692">
<arrowlink DESTINATION="ID_93811717"/>
</node>
<node TEXT="分数函数的导数和Sigmoid函数的导数" ID="ID_1242970534" CREATED="1732850110523" MODIFIED="1732850123623"/>
<node TEXT="当f(x)在x=a处取最小值时，该函数在该点的切线的斜率（即导函数的值）为0" ID="ID_1077069617" CREATED="1732851324492" MODIFIED="1732851373141">
<node TEXT="f&apos;(a)=0是函数f(x)在x=a处取得最小值的必要条件" ID="ID_1166879339" CREATED="1732851379269" MODIFIED="1732851405926"/>
</node>
</node>
<node TEXT="2.7 神经网络的偏导数基础（多变量函数）" FOLDED="true" ID="ID_1100335558" CREATED="1732778138306" MODIFIED="1732855994272">
<node TEXT="对多变量函数求导，由于有多个变量，必须指明对哪一个变量进行求导，关于某个特定变量的导数称为偏导数(partial derivative)" ID="ID_1146859243" CREATED="1732855213280" MODIFIED="1732855278517"/>
<node TEXT="多变量函数的最小值条件" ID="ID_1382994414" CREATED="1732855517813" MODIFIED="1732855528176">
<node TEXT="拉格朗日乘数法" ID="ID_113240002" CREATED="1732855676477" MODIFIED="1732855693321"/>
</node>
</node>
<node TEXT="2.8 误差反向传播法必需的链式法则" FOLDED="true" ID="ID_1085665626" CREATED="1732778145272" MODIFIED="1732778161738">
<node TEXT="神经网络和复合函数" POSITION="bottom_or_right" ID="ID_680695755" CREATED="1732852206526" MODIFIED="1732856021252">
<node TEXT="复合函数：嵌套结构的函数f(g(x))称为f(u)和g(x)的复合函数" ID="ID_453152428" CREATED="1732856103756" MODIFIED="1732856130292"/>
</node>
<node TEXT="单变量函数的链式法则" POSITION="bottom_or_right" ID="ID_1557292523" CREATED="1732856380926" MODIFIED="1732856394249">
<node TEXT="复合函数的导数可以像分数一样使用约分" ID="ID_1375400277" CREATED="1732856869571" MODIFIED="1732856893916"/>
<node TEXT="注意：这个约分的法则不适用于dx，dy的平方等情形" ID="ID_269833304" CREATED="1732856894455" MODIFIED="1732856945610">
<icon BUILTIN="messagebox_warning"/>
</node>
</node>
<node TEXT="多变量函数的链式法则" POSITION="bottom_or_right" ID="ID_1860417481" CREATED="1732856999228" MODIFIED="1732857007770">
<node TEXT="变量z为u,v的函数，u,v分别为x,y的函数，z关于x求导时，先对u,v求导，然后与z的相应导数相乘，最后将乘积加起来" ID="ID_1663106371" CREATED="1732857128629" MODIFIED="1732857190337"/>
</node>
</node>
<node TEXT="2.9 梯度下降法的基础：多变量函数的近似公式" FOLDED="true" ID="ID_577867667" CREATED="1732778161890" MODIFIED="1732778178791">
<node TEXT="梯度下降法时确定神经网络的一种代表性的方法，使用时要用到多变量函数的近似公式" ID="ID_1022712607" CREATED="1732858695983" MODIFIED="1732858732180"/>
<node TEXT="单变量函数的近似公式" ID="ID_1789279757" CREATED="1732858739963" MODIFIED="1732858745503"/>
<node TEXT="多变量函数的近似公式" ID="ID_1451099656" CREATED="1732858739963" MODIFIED="1732874369490"/>
<node TEXT="近似公式的向量表示" ID="ID_1605166502" CREATED="1732878978721" MODIFIED="1732878988343">
<node TEXT="泰勒展开式：近似公式的一般化公式" ID="ID_109862773" CREATED="1732880843321" MODIFIED="1732881057494"/>
</node>
</node>
<node TEXT="2.10 梯度下降法的含义和公式" FOLDED="true" ID="ID_413983021" CREATED="1732778178961" MODIFIED="1732778190156">
<node TEXT="应用数学最重要的任务之一就是寻找函数取最小值的点" ID="ID_780138602" CREATED="1732881264570" MODIFIED="1732881284277">
<node TEXT="著名的找最小值的点的方法--梯度下降法" ID="ID_1896012200" CREATED="1732881291032" MODIFIED="1732881306139"/>
</node>
<node TEXT="梯度下降法的思路" ID="ID_1582730654" CREATED="1732881313496" MODIFIED="1732881339226">
<node TEXT="在函数取最小值的点的附件，函数的增量为0（必要条件）" ID="ID_1162619167" CREATED="1732881464413" MODIFIED="1732881484688"/>
<node TEXT="数值分析领域，梯度下降法也称为最速下降法" ID="ID_402319782" CREATED="1732882456074" MODIFIED="1732882478942"/>
</node>
<node TEXT="近似公式和内积的关系" ID="ID_1358052353" CREATED="1732882482343" MODIFIED="1732882487729">
<node TEXT="z=f(x,y), z的近似变化可以表示为两个向量的内积，这是梯度下降法的出发点" ID="ID_1761333620" CREATED="1732883076098" MODIFIED="1732883129488"/>
<node TEXT="当向量b满足b = -ka时，使得内积a.b取最小值，这是梯度下降法的数学基础" ID="ID_1801309160" CREATED="1732883039030" MODIFIED="1732883070948"/>
</node>
<node TEXT="二变量函数的梯度下降法的基本式" ID="ID_107559119" CREATED="1732883141310" MODIFIED="1732883153888"/>
<node TEXT="梯度下降法及其用法" ID="ID_40482791" CREATED="1732886430467" MODIFIED="1732886439040"/>
<node TEXT="哈密顿算子 nabla" ID="ID_644640276" CREATED="1732886712498" MODIFIED="1732886770473"/>
</node>
<node TEXT="2.11 用Excel体验梯度下降法" ID="ID_1712898681" CREATED="1732778190320" MODIFIED="1732778199539"/>
<node TEXT="2.12 最优化问题和回归分析" ID="ID_952897795" CREATED="1732778199696" MODIFIED="1732778208127">
<node TEXT="从数学上来说，确定神经网络的参数是一个最优化问题，具体就是对神经网络的参数（即权重和偏置）进行拟合，使得神经网络的输出与实际数据相吻合" ID="ID_547261836" CREATED="1732892859553" MODIFIED="1732892913467"/>
<node TEXT="回归分析" ID="ID_1158657605" CREATED="1732892930808" MODIFIED="1732892934218">
<node TEXT="由多个变量组成的数据中，着眼于其中一个特定的变量，用其余的变量来解释这个特定的变量的方法" ID="ID_24571560" CREATED="1732892937984" MODIFIED="1732892981218"/>
<node TEXT="一元线性回归分析是以两个变量组成的数据为参考对象的" ID="ID_1117588402" CREATED="1732892989341" MODIFIED="1732893009194">
<node TEXT="用一条直线近似地表示散点图上的点列，通过该直线的方程来考察两个变量的关系的方法；这条近似地直线称为回归直线" ID="ID_808120718" CREATED="1732893044249" MODIFIED="1732893159916"/>
</node>
</node>
<node TEXT="代价函数 cost function" ID="ID_1779752708" CREATED="1732894793013" MODIFIED="1732894808337">
<node TEXT="利用平方误差的总和CT进行最优化的方法叫做最小二乘法" ID="ID_1288616626" CREATED="1732894833200" MODIFIED="1732894872419"/>
</node>
<node TEXT="模型参数的个数" ID="ID_1435325325" CREATED="1732894887394" MODIFIED="1732894893341">
<node TEXT="要确定模型，就必须准备好规模大于参数个数的数据" ID="ID_487289729" CREATED="1732894940058" MODIFIED="1732894962581"/>
</node>
</node>
</node>
<node TEXT="3. 神经网络的最优化" POSITION="bottom_or_right" ID="ID_1203090043" CREATED="1732756752431" MODIFIED="1732756758943">
<node TEXT="3.1 神经网络的参数和变量" ID="ID_332911629" CREATED="1732855926312" MODIFIED="1732855933490"/>
<node TEXT="3.2 神经网络的变量的关系式" ID="ID_8742043" CREATED="1732855933651" MODIFIED="1732855939503">
<node TEXT="神经网络的变量的矩阵表示" ID="ID_327933792" CREATED="1733020778791" MODIFIED="1733020790416"/>
</node>
<node TEXT="3.3. 学习数据和正解" ID="ID_1007749374" CREATED="1732855939683" MODIFIED="1732855946934">
<node TEXT="回归分析的学习数据和正解" ID="ID_891477136" CREATED="1733020808227" MODIFIED="1733020815193">
<node TEXT="利用事先提供的数据（学习数据）来确定权重和偏置，这在神经网络中称为学习" ID="ID_1724004955" CREATED="1733020988434" MODIFIED="1733021029252">
<arrowlink DESTINATION="ID_1961352918"/>
</node>
</node>
</node>
<node TEXT="3.4 神经网络的代价函数" ID="ID_31103986" CREATED="1732855947162" MODIFIED="1732855954612"/>
<node TEXT="3.5 用Excel体验神经网络" ID="ID_1919985245" CREATED="1732855954779" MODIFIED="1732855961837"/>
</node>
<node TEXT="4. 神经网络和误差反向传播法" FOLDED="true" POSITION="bottom_or_right" ID="ID_569063129" CREATED="1732756759534" MODIFIED="1732756770022">
<node TEXT="4.1 梯度下降法的回顾" ID="ID_1886137632" CREATED="1732849863276" MODIFIED="1732849873459"/>
<node TEXT="4.2 神经单元误差" ID="ID_411230293" CREATED="1732849873593" MODIFIED="1732849878630"/>
<node TEXT="4.3 神经网络和误差反向传播法" ID="ID_93811717" CREATED="1732849878787" MODIFIED="1732849890097"/>
<node TEXT="4.4 用Excel体验神经网络的误差反向传播法" ID="ID_1601459306" CREATED="1732849890338" MODIFIED="1732849906984"/>
</node>
<node TEXT="5. 深度学习和卷积神经网络" POSITION="bottom_or_right" ID="ID_1652979664" CREATED="1732756772756" MODIFIED="1732756783445"/>
</node>
</map>
