 AI Fundamentals

# 0. Credly Account Info

# 1. Intro to AI

Learning Points:

- Define artificial intelligence
- Describe three levels of artificial intelligence
- Describe the history of AI from the past to the possible future
- Define and describe machine learning
- Differentiate between structured and unstructured data
- Describe how machine learning structures data
- Describe how machine learning structures unstructured data
- Describe how machine learning uses probabilistic calculation to solve problems
- Describe three methods by which machine learning analyzes data
- Describe an ideal relationship between humans and machine learning


## 1.0 Course Overview

### About this Course

After completing this course, you should be able to:



- Define artificial intelligence
- Differentiate between AI and augmented intelligence
- Describe three levels of artificial intelligence
- Describe the history of AI, from the past to the possible future
- Define and describe machine learning
- Differentiate between structured, unstructured, and semi-structured data
- Describe how machine learning structures unstructured data
- Describe how machine learning uses probabilistic calculation to solve problems
- Describe three methods by which machine learning analyzes data
- Describe an ideal relationship between humans and machine learning


### Earn a Credential!

### Course Design

## 1.1 Module 1: What is AI?

### About this Module

#### Three levels of predictions that AI can make

##### Narrow

##### Broad

##### General

### What is AI?
 
Artificial Intelligence (AI) refers to the ability of a machine tolearn patterns andmake predictions.


#### AI does not replace human decisions; instead, AI add values to human judgment.
 
AI is a field that combinescomputer science  and robustdataset to enable problem-solving.


### What is the difference between AI and Augmented Intelligence?

#### Augmented intelligence has a modest goal of helping humans with tasks that are not practical to do.

##### Augmented intelligence allows humans to make final decisions after analyzing data, reports, and other types of data

##### Augmented intelligence acts on behalf of people in the physical world in a way that complements human abilities

#### Artificial intelligence has a lofty goal of mimicking human thinking and processes.

##### AI performs tasks without human intervention and completes mundane and repetitive tasks for humans

#### AI today is not mature enough to perform independent tasks such as diagnosing cancer.

#### Machines vs. Humans

##### Machines

###### Ingesting Large Amount of Data

###### Repetitive Tasks

###### Accurate

##### Humans

###### Generalizing Information

###### Creativity

###### Emotional Intelligence

### What does AI do?

#### Artificial intelligence machines (researchers call them "AI Services") don't think. They calculate.

##### They represent some of the newest, most sophisticated calculating machines in human history.
 
Some can perform what's calledmachine learning  as they acquire new data.

 
Others, using calculations arranged in ways inspired by neurons in the human brain, can even performdeep learning  with multiple levels of calculations.


#### Two parts of AI Services Calculate

##### Analysis

###### AI services can take in (or “ingest”) enormous amounts of data. They can apply mathematical calculations to analyze data, sorting and organizing it in ways that would have been considered impossible only a few years ago.

##### Prediction

###### AI services can use their data analysis to make predictions. They can, in effect, say, “Based on this information, a certain thing will probably happen.”
 
AI Services based on dataanalysis, makeprediction.


### What Predictions can AI Make?

#### Prediction aren't always accurate. But if they're correct often enough, they're useful and can save your time.

#### More ways that AI uses data to make predictions

##### Human Language

###### Online chatbots use natural language processing (NLP) to analyze poorly typed or spoken questions, then predict which answers to give on topics ranging from shipping or business hours to merchandise and sizes.

##### Vision Recognition

###### AI helps doctors identify serious diseases based on unusual symptoms and early-warning signs, and it reads speed limit and stop signs as it guides cars through traffic.

##### Fraud Detection

###### AI analyzes patterns created when thousands of bank customers make credit card purchases, then predicts which charges might be the result of identity theft.

### How is AI Evolving?

#### Narrow AI (2010-2015)

##### Narrow AI si focused on addressing a single task such as predicting your next purchase or planning your day

##### Narrow AI is scaling very quickly in the consumer world, in which there are a lot of common tasks and data to train AI systems. e.g., you can buy a book with a voice-based device.

##### Narrow AI also enables robust applications, such as using Siri on an iPhone, the Amazon recommendation engine, autonomous vehicles, and more. Narrow AI systems like Siri have conversational capabilities, but only if you stick to the script.

#### Broad AI (AI for Enterprise) (Today), We are here

##### Broad AI is a midpoint between Narrow and Genaral AI

##### Rather than being limited to a single task, Broad AI systems are more versatile and can handle a wider range of related tasks

##### Broad AI is focused on integrating AI within a specific business process where companies need business- and enterprise-specific knowledge and data to train this type of system

##### New Broad AI systems predict global weather, trace pandemics, and help businesses predict future trends

#### General AI (2050 and beyond)

##### General AI refers to machines that can perform any intellectual task that a human can

##### Currently, AI does not have the ability to think abstractly, strategize, and use previous experiences to come up with new, creative ideas as humans do, such as inventing a new product or responding to people with appropriate emotions. And don't worry, AI is nowhere near this point.

#### Artificial Superintelligence (ASI) (near the end of this century)

##### Machine might become self-aware!

## 1.2 Module 2: What are the three eras of computing?

### About this Module

#### Describe the history of AI, from the past to the possible future

### The Era of Tabulation: People have analyzed data for centuries

#### Dark Data

##### Dark Data: it's information without structure, just a huge, unsorted mess of facts.

#### Unstructured Data

##### Over 2000 years ago, tax collectors for Emperor Qin Shihuang used the abacus—a device with beads on wires—to break down tax receipts and arrange them into categories. From this, they could determine how much the Emperor should spend on building extensions to the Great Wall of China.

##### In England during the mid-1800s, Charles Babbage and Ada Lovelace designed (but never finished) what they called a “difference engine” designed to handle complex calculations using logarithms and trigonometry. Had they built it, the difference engine might have helped the English Navy build tables of ocean tides and depth soundings that could guide English sailors through rough waters.

##### By the late 1880s, people were thinking about how to develop faster systems to record data. Herman Hollerith, inspired by train conductors using holes punched in different positions on a railway ticket to record traveler details, invented the recording of data on a machine-readable punched card. Hollerith’s cards were used for the 1890 US Census, which finished months ahead of schedule and under budget. Later versions of tabulating machines had broad applications in business, such as financial accounting and data processing.

#### The word to remember across those twenty centuries is tabulate. Think of tabulation as “slicing and dicing” data to give it a structure, so that people can uncover patterns of useful information. You tabulate when you want to get a feel for what all those columns and rows of data in a table really mean.

#### Researchers call these centuries the Era of Tabulation, a time when machines helped humans sort data into structures to reveal its secrets.

#### Machines helped humans sort data into structures to reveal its secrets, that is, to reveal more insight than just simply counting to get a sum total

### The Era of Programming: Data analysis changed in the 1940s

#### During the turmoil of World War II, a new approach to dark data emerged: the Era of Programming. Scientists began building electronic computers, like the Electronic Numerical Integrator and Computer (ENIAC) at the University of Pennsylvania, that could run more than one kind of instruction (today we call those “programs”) in order to do more than one kind of calculation. ENIAC, for example, not only calculated artillery firing tables for the US Army, it worked in secret to study the feasibility of thermonuclear weapons.

##### This was a huge breakthrough. Programmable computers guided astronauts from Earth to the moon and were reprogrammed during Apollo 13’s troubled mission to bring its astronauts safely back to Earth.

#### You’ve grown up during the Era of Programming. It even drives the phone you hold in your hand. But the dark data problem has also grown. Modern businesses and technology generate so much data that even the finest programmable supercomputer can't analyze it before the “heat-death” of the universe. Electronic computing is facing a crisis.

### The Era of AI: a brief history of AI

#### The history of artificial intelligence dates back to philosophers thinking about the question, "What more can be done with the world we live in?" This question lead to discussions and the very beginning of many ideas about the possibilities involving technology.

#### 1940s: Turing Machine

##### Alan Turing publishes Computing Machinery and Intelligence. In the paper, Turing—famous for helping to break the Nazis’ Enigma code during World War II—proposes to answer the question "can machines think?" and introduces the Turing Test to determine if a computer can demonstrate the same intelligence (or the results of the same intelligence) as a human.

#### 1940s: Analogue Robots

#### 1950: Turing Test

#### 1951: Minsky Neural Net

#### 1956: Dartmouth Conference, Birth of AI

##### John McCarthy coins the term "artificial intelligence at the first-ever AI conference at Dartmouth College. Later that year, Allen Newell, J.C. Shaw, and Herbert Simon create the Logic Theorist, the first-ever running AI software program. McCarthy would go on to invent the Lisp language.

##### The researchers proposed that “every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it.” They called their vision “artificial intelligence” and they raised millions of dollars to achieve it within 20 years. During the next two decades, they accomplished tremendous things, creating machines that could prove geometry theorems, speak simple English, and even solve word problems with algebra.

#### 1957: Checkers

#### 1960s: Semantic Networks

#### 1966: ELIZA

#### 1969: SHRDLU Born

#### 1970-80: 1st AI Winter - K9, Star Wars
 
1st AI Winter caused byhigh expectations from end users andreduced funding.


###### Limited calculating power
Today, it is important for a computer to have enough processing power and memory. Every ad you see for companies like Apple or Dell emphasizes how fast their processors run and how much data they can work with. But in 1976, scientists realized that even the most successful computers of the day, working with natural language, could only manipulate a vocabulary of about 20 words. But a task like matching the performance of the human retina might require millions of instructions per second, at a time when the world’s fastest computer could run only about a hundred. By the early 1970s, it became clear that the problem was larger than researchers imagined. There were fundamental limits that no amount of money and effort could solve.

###### Limited information storage
Even simple, commonsense reasoning requires a lot of information to back it up. But no one in 1970 knew how to build a database large enough to hold even the information known by a 2-year-old child.

#### 1982: Expert Systems - ZX81

#### 1982: Hopfield Net/Back Propagation

#### 1982 to 1993: 2nd AI Winter - Joined IBM

##### 2nd AI Winter caused by unmet expectations and computing power.

##### Over 300 AI companies shut down or went bankrupt during The Second Winter of AI.

#### 1997: Deep Blue Beats Kasparov (chess)

#### 2005: DARPA Grand Challenge (self driving vehicle)

#### 2011: Watson Wins Jeopardy (quiz show)

##### IBM Watson beats champions Ken Jennings and Brad Rutter at the US game show called Jeopardy!

#### 2016: AlphaGo (Go)

##### DeepMind's AlphaGo program, powered by a deep neural network, beats Lee Sodol, the world champion Go player, in a five-game match. The victory is significant given the huge number of possible moves as the game progresses (over 14.5 trillion after just four moves!). Google bought DeepMind for a reported USD 400 million in 2014.

#### 2017: Alpha Zero - K9 Mk 1

#### 2019: Project Debater

##### IBM unveils Project Debater, the first AI system capable of engaging with humans on complex topics in a live debate.

#### 2022: K9 Mk2

## 1.3 Module 3: Structured, Semi-Structured, and Unstructured Data

### About this Module

#### Data is raw information. Data might be facts, statistics, opinions, or any kind of content that is recorded in some format. This could include voices, photos, names, and even dance moves!

### A look at the types of Data

#### Structured Data

##### Structured data is typically categorized as quantitative data and is highly organized. Structured data is information that can be organized in rows and columns. Perhaps you've seen structured data in a spreadsheet, like Google Sheets or Microsoft Excel. Examples of structured data includes names, dates, addresses, credit card numbers, stock information.

###### Sample: hotel and ticket reservation data

###### Sample: flight schedule

#### Unstructured Data (Dark Data)

##### Unstructured data, also known as dark data, is typically categorized as qualitative data. It cannot be processed and analyzed by conventional data tools and methods. Unstructured data lacks any built-in organization, or structure. Examples of unstructured data include images, texts, customer comments, medical records, and even song lyrics.

###### Sample: social media posts

###### Why would anyone want to search through a mountain of data such as social media posts?

* A sneaker designer looking for new trends

* Governments searching for possible terrorists

* Pandemic experts trying to anticipate disease outbreaks

* Financial institutions preparing for good times or a recession

##### The importance of unstructured data is rapidly increasing. Recent projections(opens in a new tab) indicate that 95% of businesses prioritize unstructured data management.
 
Experts estimate that about80% of all the data in today’s world is unstructured. It contains so many variables and changes so quickly that no conventional computer program can learn much from it.

 
Unstructured data is categorized asqualitative  data, and cannot be processed and analyzed by conventional data tools and methods


#### Semi-Structured Data

##### Semi-structured data is the “bridge” between structured and unstructured data. It doesn't have a predefined data model. It combines features of both structured data and unstructured data. It's more complex than structured data, yet easier to store than unstructured data. Semi-structured data uses metadata to identify specific data characteristics and scale data into records and preset fields. Metadata ultimately enables semi-structured data to be better cataloged, searched, and analyzed than unstructured data. An example of semi-structured data is a video on a social media site. The video by itself is unstructured data, but a video typically has text for the internet to easily categorize that information, such as through a hashtag to identify a location.

###### Sample: tweets organized by hashtags

##### Data that is not completely raw and contains elements such as tags and organizational metadata is known as semi-structured data

### Analyzing Unstructured Data

## 1.4 Module 4: Is Machine Learning the Answer to the Unstructured Data Problem?

### About this Module

Define and describe machine learning

Describe how machine learning structures unstructured data

Describe how machine learning uses probabilistic calculation to solve problems


### How does ML Approach a Problem?

#### Consider the problem of finding a route through big city traffic using a navigation system: ML Process's advantages

##### It doesn't need a DB of all the possible routes from one place to another. It just needs to know where places are on the map.

##### It can respond to traffic problems quickly because it doesn't need to store alternative routes for every possible traffic situation. It notes where slowdowns are and finds a way around them through trial and error.

##### It can work very quickly. While trying single turns one at a time, it can work through millions of tiny calculations.

#### Other ML's advantages that programmable computers lack

##### Machine learning can predict

##### Machine learning learns!

#### Machine Learning can analyze Dark Data (unstructured data) more quickly than a programmable computer can

### ML uses Probabilistic Calculation

#### Two other ways to contrast classical and machine learning systems

##### Deterministic

###### For a deterministic system, there must be an enormous, predetermined structure of routes—a gigantic database of possibilities from which the machine can make its choice. If a certain route leads to the destination, then the machine flags it as “YES”. If not, it flags it as “NO”. This is basically binary thinking: on or off, yes or no. This is the essence of a computer program. The answer is either true or false, not a confidence value.

##### Probabilistic

###### It never says “YES” or “NO”. Machine learning is analog (like waves gradually going up and down) rather than binary (like arrows pointing upward and downward). Machine learning constructs every possible route to a destination and compares them in real time, including all the variables such as changing traffic. So, a machine learning system doesn’t say, “This is the fastest route.” It says something like, “I am 84% confident that this route will get you there in the shortest time.” You might have seen this yourself if you’ve traveled in a car with an up-to-date GPS navigation system that offers you two or three choices with estimated times.

#### Machine learning enables a rich partnership between technology and humans

##### AI systems and humans excel at different things. For example, you, as a person, might excel at imagining possibilities, while AI excels at pinpointing patterns.

##### AI Capabilities

###### Pattern Identification

###### Machine Learning

###### Structuring information

###### Endless memory capacity

##### Human capabilities

###### Abstraction

###### Compassion

###### Generalization

###### Dreaming

#### Does Common Sense make sense?

##### Common sense draws on many complex generalizations mixed with compassion and abstractions. At this time, only humans can use common sense well. The problem is that common sense is often tainted with bias that can distort your judgment. AI systems can balance this. As long as AI systems are provided and trained with unbiased data, they can make recommendations that are free of bias. A partnership between humans and machines can lead to sensible decisions.

## 1.5 Module 5: Three Common Methods of Machine Learning

### About this Module

Describe three methods by which machine learning analyzes data


### Supervised Learning

#### is about providing AI with enough examples to make accurate predictions

#### All Supervised Learning algorithms need labeled data.

##### Labeled data is data that is grouped into samples that are tagged with one or more labels.
 
In other words, applying supervised learning requires you to tell your model:

1. What the key characteristics of a thing are, also calledfeatures

2. What the thing actually is


#### Example: Classification Problem

##### For example, the information might be drawings and photos of animals, some of which are dogs and are labeled “dog”. The machine will learn by identifying a pattern for “dog”. When the machine sees a new dog photo and is asked, “What is this?”, it will respond, “dog”, with high accuracy. This is known as a classification problem.

### Unsupervised Learning

#### A person feeds a machine a large amount of information, asks a question, and then the machine is left to figure out how to answer the question by itself.

##### For example, the machine might be fed many photos and articles about dogs. It will classify and cluster information about all of them. When shown a new photo of a dog, the machine can identify the photo as a dog, with reasonable accuracy.

#### Example: Clustering Information
 
Unsupervised learning occurs when the algorithm is not given a specific “wrong” or “right” outcome. Instead, the algorithm is givenunlabeled data.


##### Unsupervised learning is helpful when you don't know how to classify data. For example, imagine you work for a banking institution and you have a large set of customer financial data. You don't know what type of groups or categories to organize the data. Here, an unsupervised learning algorithm could find natural groupings of similar customers in a database, and then you could describe and label them.
 
This type of learning has the ability to discoversimilarities  anddifferences in information, which makes it an ideal solution for exploratory data analysis, cross-selling strategies, customer segmentation, and image recognition.


### Reinforcement Learning

#### A machine learning model similar to supervised learning, but the algorithm isn't trained using sample data. This model learns as it goes by using trial and error.

##### A sequence of successful outcomes is reinforced to develop the best recommendation for a given problem.

##### The foundation of reinforcement learning is rewarding the "right" behavior and punishing the "wrong" behavior

##### Rewording a machine means that you give your agent positive reinforcement for performing the "right" thing and negative reinforcement for performing the "wrong" thing

#### Example: Trial and Error

#### As a machine learns through trial and error, it tries a prediction, then compares it with data in its corpus.

##### Each time the comparison is positive, the machine receives positive numerical feedback, or a reward.

##### Each time the comparison is negative, the machine receives negative numerical feedback, or a penalty.

#### Over time, a machine’s predictions will grow to be more accurate. It accomplishes this automatically based on feedback, rather than through human intervention.

## 1.6 Module 6: How will Machine Learning Transform Human Life?

### About this Module

Describe an ideal relationship between humans and machine learning


### Take another look at the Three Levels of AI

#### AI researcher Nick Bostrom defines this superintelligence as, “an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills.” You’re likely to see General AI appear in your lifetime. General AI will enable supersmart bots and technologies to link AI with the Internet of Things through “embodied cognition”. This will give machines the ability to interact in human-like ways as they work alongside humans.

### What will interacting with general AI feel like to humans?

#### AI everywhere

##### AI will move into all industries, from finance, to education, to healthcare. AI will increase productivity and enable new opportunities.

#### Deeper insights

##### New technologies will sense, analyze, and understand things never before possible.

#### Engagement reimagined

##### New forms of human-machine interaction and emerging technologies, such as conversational bots, will transform how humans engage with each other and with machines.

#### Personalization

##### Machine interactions will be personalized for you, with new levels of detail and scale.

#### Instrumented planet

##### Billions of sensors generating exabytes of data will open new possibilities for improving Earth’s safety, sustainability, and security.

### What’s beyond these wonders? Humans, devices, and robots might exist as a collective “digital brain” that anticipates human needs, makes predictions, and provides solutions. Farther in the future, we might trust the digital brain to do things on our behalf across a broad spectrum of endeavors!

### “How does machine learning enable decision-making in complex scenarios, such as medical treatment choices?”

#### By providing probabilistic statements with confidence levels for different treatment options

## 1.7 Summary and Final Assessment

Explore More:



- What Is Artificial Intelligence (AI)?(opens in a new tab) – A detailed look into artificial intelligence from IBM provides more information on types of AI, the history of AI, and the future of AI.
- Structured vs. Unstructured Data: What’s the Difference?(opens in a new tab) – IBM Cloud experts provide examples comparing the pros and cons of structured and unstructured data.
- Distinguishing between Narrow AI, General AI and Super AI(opens in a new tab) – A simple, but necessary guide offered by Medium.
- What is generative AI?(opens in a new tab) - An IBM Research expert provides an introduction to generative AI and how it works.
- Humans vs. AI: who makes the best decisions?(opens in a new tab) – IBM Master Inventor Martin Keene answers the question, “Who makes the best decisions, humans or AI?”
- Can AI Help Climate Change?(opens in a new tab) – In this video, Stacey Gifford, an IBM Research chemist, explains how artificial intelligence can be used to develop new materials to help address climate change.


### 1. Artificial intelligence refers to the ability of a machine to learn patterns and make predictions. AI does not replace human decisions; instead, AI adds value to human judgment.

### 2. AI performs tasks without human intervention and completes mundane and repetitive tasks, while augmented intelligence allows humans to make final decisions after analyzing data, reports, and other types of data.

### 3. The three levels of AI include: Narrow AI, Broad AI, and General AI. Narrow AI and Broad AI are available today. In fact, most enterprises use Broad AI. General AI won’t come online until sometime in the future.

### 4. The history of AI has progressed across the Era of Tabulation, Era of Programming, and Era of AI.

### 5. Data can be structured, unstructured, or semi-structured.

#### Structured data is quantitative and highly organized, such as a spreadsheet of data.

#### Unstructured data is qualitative data that doesn't have structure, such as medical records. It's becoming increasing valuable to businesses.

#### And semi-structured data combines features of both structured data and unstructured data. It uses metadata.

### 6. About 80% of all the data in today’s world is unstructured.

### 7. Machine learning has advantages compared to programmable computers. Machine learning can predict and machine learning learns!

### 8. Machine learning uses three methods.

#### Supervised learning requires enough examples to make accurate predictions.

#### Unsupervised learning requires large amounts of information so the machine can ask a question, and then figure out how to answer the question by itself.

#### Reinforcement learning requires the process of trial and error.

### 9. With AI everywhere, AI will move into all industries, from finance, to education, to healthcare.

### 10. AI can increase productivity, create new opportunities, provide deeper insights, and enable personalization.

# 2. Natural Language Processing and Computer Vision

What you’ll learn

After completing this course, you should be able to:

 

- Define natural language processing
- Explain how AI uses natural language processing to derive meaning from text
- Explain the classification problem and its solutions
- Describe how a chatbot understands, reasons, learns, and interacts with users
- Distinguish between intents, entities, and dialogs
- Identify appropriate uses for chatbots
- Identify real-world uses for natural language processing (NLP)
- Describe how AI classifies images to derive meaning from them
- Describe how a convolutional neural network(CNN) analyzes an image
- Describe how a generative adversarial network (GAN) creates a credible image
- Identify real-world uses for computer vision


## M1: The Debater Project

### A system that helps machines understand cultural knowledge, grammatical structures, and various language nuances is known as natural language processing

#### IBM Project Debater was a major step forward in the field of natural language processing.

#### Human language is complex, so machines require natural language processing systems to understand human language.

### Project Debater

#### IBM began developing Project Debater in 2012, hoping to build a machine that could do more than win debates with humans. In other words, IBM Project Debater would need to be able to do more than just answer questions in a human language; it would need to have the ability to listen to a series of competitive arguments posed by humans and respond to them intelligently. IBM's ultimate goal was to build a system that could help people make evidence-based, bias-free decisions on difficult topics where the answers aren’t obvious.

### Debate Steps

#### 1. Learn and Understand the Topic
 
Ingest several billion passages from newspapers, books, and journals. (AI researchers call this collection of learned material acorpus.语料库) Then, structure all that content so you can relate concepts to each other and evaluate them, even when they’re stated in different ways.


#### 2. Build a Position

##### Create an opening speech made of short pieces of text pasted together from the corpus. Your speech should detail your position on the debate topic. It can’t be a jumble of phrases. It must present a compelling argument, in logical order, using good grammar.

#### 3. Organize your Proof

##### Learn the deeper meaning of the facts that surround your topic. Decide what evidence is strongest and arrange your proof by themes. Adjust your arrangement each time new evidence arrives. This will help you find updated or completely new information that can score points against your opponent’s position.

#### 4. Respond to Your Opponent

##### Listen to your opponent’s arguments and rebuttals, then deliver a convincing rebuttal that refutes your opponent and further proves your case.

### Why do we care about these four steps? Because they reflect and test four things that cognitive systems do

#### Understanding

##### Cognitive systems understand like humans do

#### Reasoning

##### They reason underlying ideas and concepts.
They debate.
They infer and extract concepts.

他们推理潜在的思想和概念。

他们辩论。

他们推断并提取概念。


#### Learning

##### They never stop learning.
Advancing with each new piece of information, interaction, and outcome.
They develop "expertise".

#### Interacting

##### ... Allowing them to interact with humans.

### Steps in NLP

#### Understanding human language is difficult, even for people who have grown up with it. Human language is incredibly complex, full of strange expressions that seem to contradict each other, metaphors that require cultural knowledge to understand, and grammatical structures that sometimes turn simple ideas into tongue-twisters.

理解人类语言并非易事，即使对从小就接触人类语言的人来说也是如此。人类语言极其复杂，充满了看似自相矛盾的奇特表达、需要文化知识才能理解的隐喻，以及有时会将简单的想法变成绕口令的语法结构。


#### Machines require systems that research scientists call natural language processing, or NLP, to understand human language. IBM Project Debater was the most complex AI system IBM Research had ever built to understand human language.

## M2: AI Performs NLP

### About this Module

Explain how AI uses natural language processing to derive meaning from text

Explain the classification problem and its solutions


### NPL Sentence Segmentation and Tokens

#### In NLP, machines segment sentences and extract meaning from “tokens” of human language

#### Human language is unstructured. Although it is loosely held together by rules of grammar, our language expresses information in many confusing ways. Unlike structured information, which can be arranged in tables or matrices with neatly labeled rows and columns, unstructured information is messy and difficult to understand. To see why, consider this famous joke by Groucho Marx.
 
To deal with the “messiness” of unstructured information, computers begin with one sentence at a time. This is calledsentence segmentation. Computers then break the information into small chunks of information, calledtokens, that can be individually classified. Once the tokens in text have been sorted into a structure based on what they mean, NLP can work with them.


为了处理非结构化信息的“混乱”，计算机会从逐句开始处理。这被称为句子分割。然后，计算机将信息分解成小块信息，这些小块被称为“标记”，可以单独进行分类。一旦文本中的标记根据其含义被分类成结构，NLP 就可以对其进行处理。


#### "One morning I shot an elephant in my pajamas. How he got in my pajamas, I don’t know.

Adapted from Groucho Marx, 20th century comedian and movie star

##### Activity 1: Entities

###### An entity is a noun representing a person, place, or thing. It’s not an adjective, verb, or other article of speech.

###### I, elephant, and pajamas are entities because they are nouns.
Shot, an, in, and my are not entities because they are not nouns.

##### Activity 2: Relationships

###### A relationship is a group of two or more entities that have a strong connection to one another.

###### For I + elephant, I + pajamas, and elephant + pajamas, both words in the pair are nouns and are related entities.

I + shot is not a relationship between entities. I is a noun but shot is a not.

in + pajamas is not a relationship between entities. Pajamas is a noun but in is not.

###### Once an AI has classified entities and relationships in text or speech, the AI can begin structuring the information as a step toward understanding it. Your brain, by the way, does the same thing, which might have helped you find entities and relationships in the previous activities.

###### For example, consider the following two sentences: “Armen broke the glass. He always breaks the glass.” Notice that there is a relationship between the two sentences: the word he is related to the word Armen. The machine uses NLP to identify this relationship.

##### Activity 3: Concepts

###### A concept is something implied in a sentence but not actually stated. This is trickier because it involves matching ideas rather than the specific words present in the sentence.

### Emotion Detection and Sentiment Analysis

#### Emotion detection identifies distinct human emotion types.

情绪检测可以识别人类不同的情绪类型。


##### For example, you can determine if the emotion being expressed is anger, happiness, or fear after reading a user's rating and comments in an online customer satisfaction survey.

##### AI can be trained to classify emotions. Identifying the right emotional token can make a big difference when an AI system is reading a social media post or a customer service chat, in which different emotions significantly change the meaning of a sentence.

#### Sentiment analysis isn’t a specific emotion —at least, not as computer scientists use the term. Instead, it’s a measure of the strength of an emotion.

情绪分析并非指代某种特定的情绪——至少，计算机科学家不是这么称呼它的。相反，它是对情绪强度的衡量。


##### You can think of sentiment as a sliding scale between positive and negative, with neutral in the middle.

##### Sentiment analysis is a means of assessing if data is positive, negative, or neutral.

##### Sentiment Analysis is A method to measure the strength of an emotion by assessing data as positive, negative, or neutral

### The Classification Problem

#### Human Language makes classification challenging --
Human language is full of terms that are vague or have double meanings. This is called a classification problem. In the riddle, run and smell each have two meanings.

##### "A runny nose" means you have a cold and you need a tissue to wipe your nose.

##### "A smelly foot" means that your  foot has an unpleasant odor.
 
Classification can be more difficult for an AI system than identifying tokens because so much of classification depends on the context in which a sentence is contained.


##### Compare I went to the docks to ship my box to I went to the station to ship my box. Both sentences indicate where a box’s travel begins, but neither specifies how it will travel. An AI system must associate the word ship with either the word station or docks, and then relate that association with the right concept: either train or boat.

##### How does an AI system deal with this problem? After ingesting several thousand instances in which shipping from a dock results in boat travel, while shipping from a station leads to shipping by rail, the AI system identifies the frequency in which places and kinds of travel are linked. Gradually, the system gets better at classification and makes fewer mistakes. However, as with humans, an AI system’s classification will never be 100% perfect. (That’s why well-designed AI systems give not only a response, but also a confidence value.)

#### As you’ve learned, getting from tokens and classification to answering questions (or winning a debate) is a complex endeavor. But it isn’t enough to take a machine all the way to understanding. You will learn about ways to do this later in this course.

### NLP and Jeopardy!
 
AI system is working with human language handle the classification problem bylearning from many instances.


## M3: Chatbots use NLP to Interact with Humans

### About this Module

#### Describe how a chatbot understands, reasons, learns, and interacts with users

#### Distinguish between intents, entities, and dialogs

#### Identify appropriate uses for chatbots

#### Identify real-world uses for natural language processing

### Chatbot Structure

#### Chatbots work with small data. This means their scale is much more limited.

#### A Chatbot has a "frontend" and a "backend"

##### The frontend of a chatbot is the messaging channel. The frontend interacts with the person who’s asking questions, both listening (or reading) and speaking (or presenting text).

###### User Interaction

##### The backend of a chatbot is where the hard work takes place. The backend operates application logic and has enough memory to remember earlier parts of a conversation as dialog continues.
 (see:)
###### Logic

###### Data

### The Chatbot Backend
 
A chatbot’s backend does the hard work ofunderstanding  andresponding

 
This is a great job for algorithms calledclassifiers.


##### Classifiers can map many different ways of asking a question to a very small set of answers. How small? Some retail chatbots respond to hundreds of different questions with only five or six possible answers. Questions the chatbots can’t answer are sent to human customer service representatives.

#### Chatbots are designed for a small set of interaction types.

### Intents, Entities, and Dialog

#### A ChatBot backend usually includes 3 parts: intents, entities, and dialog
 
Chatbots understand a question by breaking it into parts and relating those parts to things in its memory. A chatbot’s goal is to identify what are calledentities andintents, then use what it’s found to trigger adialog. What do these terms mean?


##### The chatbot breaks inputs apart to identify intents and entities.

#### Intent

##### An intent is a purpose: the reason why a user is contacting the chatbot. Think of it as something like a verb: a kind of action. A user might intend to file a complaint, to ask for directions, to speak to a salesperson.

###### A chatbot runs NLP to understand the human’s intentions of their typed input.

#### Entity
 
An entity is anoun: a person, place, or thing. This concept was covered earlier in this course.


#### Dialog

##### A dialog is a flowchart—an IF / THEN tree structure that illustrates how a machine will respond to user intents. A dialog is what the machine replies after a human asks a question. Even if a human uses run-on sentences, poor grammar, chat messaging expressions, and so on, artificial intelligence allows the NLP to understand well enough to provide a response.

###### The dialog represents each possible word or phrase a user might enter, the matched response for the chatbot, and the many possible subsequent replies a user might make next.
 
That’s too much for an ordinary flowchart to show (you might need three or four dimensions!), so chatbot software condenses each moment of the conversation into anode.


###### A node contains a statement by the chatbot and a long, expandable list of possible replies.
 
A dialog is represented by aflowchart that illustrates how a chatbot will respond after a human asks a question.


### Example NLP Analysis

#### Intents, entities, and dialogs make quick work for NLP

#### In a conventional computer, the program code is stupendously large but wouldn’t handle intents, entities, and dialogs very well. A conventional computer would need a separate IF / THEN line for many thousands of ways a question might be asked. Unless a human were to match one of those lines perfectly, the computer would fail.

#### But an AI system’s combination of NLP with intents, entities, and dialog can make quick work of this. NLP analyzes sentence components, then uses processes like passage and evidence scoring to classify the sentence components against possible chatbot responses. The result is that when a human user asks a question, the AI system provides the answer with the highest confidence.

但人工智能系统将自然语言处理 (NLP) 与意图、实体和对话相结合，可以快速完成这项工作。NLP 会分析句子成分，然后使用段落和证据评分等流程，根据聊天机器人的可能响应对句子成分进行分类。这样，当人类用户提出问题时，人工智能系统就能提供置信度最高的答案。


## M4: AI Classifies Images

### About this Module

#### Describe how AI classifies images to derive meaning from them
 
Describe how aconvolutional neural network (CNN) analyzes an image


描述卷积神经网络 (CNN) 如何分析图像

 
Describe how agenerative adversarial network  (GAN) creates a credible image


描述生成对抗网络 (GAN) 如何创建可信图像


#### Identify real-world uses for computer vision

### Convolutional Neural Networks (CNN)

#### An AI system uses a convolutional neural networks (CNN) to analyze images

##### It's one thing to display an image and another, much more complicated thing to analyze it.
 
The process - called aconvolutional neural network (CNN) - makes it possible for visual recognition systems to identify things in an image, as in facial recognition.


#### In a CNN, two small groups of pixels that overlap each other are compared mathematically to get a value. AI can use thousands of these small comparisons to identify individual parts of an image, then compare them to images in its corpus. From this, AI can put together an overall identification, without being overwhelmed.

#### CNN process makes facial recognition possible

### Generative Adversarial Networks (GAN)

#### A visual recognition system can use a generative adversarial network (GAN) to create new drawings and photos

#### One way is by pitting two convolutional neural networks (CNNs) against each other in a “contest” called a generative adversarial network, or GAN. In effect, the CNNs battle each other until one of them becomes pretty good at creating art.

#### A GAN battle ends with an image that’s ready to be shown to a human. Sometimes, the human might laugh and think the resulting image is ridiculous. But other times, the human, like the CNN acting as judge and teacher, won’t be able to tell the difference. At that point, the deep fake is a success!

### Computer Vision Applications

#### The IBM Maximo visual inspection system can be equipped with video cameras on drones. It can not only detect problems, like cracks in a suspension bridge, but identify which problems (cracks, in this example) are dangerous and should be repaired.

#### Here are more applications

##### Spotting a dangerous but difficult-to-detect flaw in an airplane’s wing

##### Monitoring water flow across a dairy farm to ensure it doesn’t reach nearby food crops

##### Counting the number of people in an unruly crowd

##### Classifying animal and plant populations to measure biodiversity in a forest

##### Performing lip-reading for people who cannot hear or speak

##### Inspecting robots at work on an assembly line

## Summary

Define natural language processing

Explain how AI uses natural language processing to derive meaning from text

Explain the classification problem and its solutions

Describe how a chatbot hears, identifies, and responds to a question

Distinguish between intents, entities, and dialogs

Identify appropriate uses for chatbots

Identify real-world uses for natural language processing

Describe how AI classifies images to derive meaning from them

Describe how a convolutional neural network (CNN) analyzes an image

Describe a generative adversarial network (GAN) creates a credible image

Identify real-world uses for computer vision



Explore more:

- What is natural language processing (NLP)?(opens in a new tab) – and IBM site that explains NLP, tools, and use cases
- What is a chatbot?(opens in a new tab) – an IBM site that explains chatbots and sets out guidance for making them more effective
-  What is computer vision?(opens in a new tab) – an IBM site focusing on computer vision and how AI derives meaningful information from digital images, videos, and other visual inputs


### 1. Machines require systems called natural language processing (NLP) to understand human language. Human language is unstructured. In NLP, machines segment sentences into small chunks of information, called a token. Machines classify and sort tokens into a structure so NLP can work with them to extract meaning.

### 2. With IBM Project Debater, the goal was to build an AI system that could help people make evidence-based, bias-free decisions on difficult topics where the answers aren’t obvious.

### 3. The four steps a debater AI system takes include:

#### Step 1: Learn and understand the topic

#### Step 2: Build a position

#### Step 3: Organize your proof

#### Step 4: Respond to your opponent

### 4. Emotion detection identifies distinct human emotion types. AI can be trained to classify emotions.

#### how detecting emotions can help an AI system in user interactions?

It enables the AI to detect when a customer is frustrated or angry and escalate the issue to a human agent.

### 5. Sentiment analysis is a measure of the strength of an emotion. It results in assessing if data is positive, negative, or neutral.

### 6. Chatbots are ready to answer your questions!

#### The frontend interacts with the person asking questions. It listens (or reads) and speaks (or presents text).

#### The backend operates application logic and has enough memory to remember earlier parts of a conversation as dialog continues.

### 7. A chatbot identifies entities and intents, then uses what it has found to trigger a dialog.

#### An intent is a purpose, or the reason why a user is contacting the chatbot. Think of it as a verb or action to take.

#### An entity is a person, place, or thing. Think of it as a noun.

#### A dialog is a flowchart that illustrates the chatbot replies to the user intents.

### 8. With a convolutional neural network (CNN), an AI system can analyze images. With a generative adversarial network (GAN), an AI system can create new drawings and photos.

### 9. NLP and computer vision can be useful ways to extend human expertise.

# 3. Machine Learning and Deep Learning

 **What you’ll learn** 

After completing this course, you should be able to:

 

- Distinguish between artificial intelligence, machine learning, and deep learning
- Describe supervised, unsupervised, and reinforcement learning
- Describe decision trees, linear regression, and logistic regression
- List and explain advantages of classical machine learning
- Describe how neural networks are inspired by the human brain
- Trace the flow of information through a perceptron’s nodes
- Describe machine learning’s trial-and-error learning process
- Define and describe deep learning and its ecosystem
- Identify real-world applications for the deep learning ecosystem
- Identify future trends for machine learning


## Overview

Learning objectives



After completing this course, you should be able to:



- Distinguish between artificial intelligence, machine learning, and deep learning
- Describe supervised, unsupervised, and reinforcement learning
- Describe decision trees, linear regression, and logistic regression
- List and explain advantages of classical machine learning
- Describe how neural networks are inspired by the human brain
- Trace the flow of information through a perceptron’s nodes
- Describe machine learning’s trial-and-error learning process
- Define and describe deep learning and its ecosystem
- Identify real-world applications for the deep learning ecosystem
- Explain generative AI and the impact in today's world
- Identify future trends for machine learning

 
The termartificial intelligence describes computer systems that can apply reasoning to subjects that previously required human intelligence

 
Machine learning can enable systems topredictandclassifygiven data in response to ever-changing data, somewhat like the way you learn from experience.

 
Deep learningis a group of extremely powerful types of machine learning, many of which are inspired by the operation ofneural networksin the human brain

 
These AI systems do not have common sense or world knowledge, nor do they have a sense of self (at least, not yet). But they do acquire knowledge and understanding through experience—a process calledcognition—accomplishing results that resemble human thinking. They do this primarily by using complex rules calledalgorithms that help them analyze data.


## M1 How do Machines Learn?

Learning objectives



After completing this module, you should be able to:



- Distinguish between artificial intelligence, machine learning, and deep learning
- Describe supervised, unsupervised, and reinforcement learning


### About this Module

### Machines learn in 3 general ways

#### AI systems use algorithms to predict and classify data points collected both from computer databases and natural occurrences. But algorithms have three general ways that they can learn from this data to get better results and provide better predictions:

- Supervised learning
- Unsupervised learning
- Reinforcement learning

### Supervised Learning
 
In supervised learning, humans give an AI system what’s called structured data. This is a set of facts and figures arranged into neat,labeled  categories, the way you might put weather information into a table.


#### Using the way the data has been structured, the AI system can detect patterns (such as day-to-day temperature changes in the table above) and use those patterns to predict future data (such as temperatures during the following week).

#### Structured data can also take the form of images.

##### If, for example, the data includes photos of flowers, some of which are roses and are labeled rose, the machine will learn things about the arrangements of pixels in those photos. Later, when it sees a new rose photo and is asked, “What is this?”, it will respond “rose”.

#### As you’ll soon discover, the machine will never give this result with absolute confidence. Instead, the system will give a confidence value to indicate, for example, that it might predict with 85% certainty that its answer is correct. The more data the system ingests, the higher its accuracy will be.

#### Example

##### An AI system ingests data that has been labeled

##### Supervised learning requires that an AI system ingest structured data.

##### Maria is involved in training the AI for her company. She separates weather data in a database into different categories.

### Unsupervised Learning

#### It has often been convenient to refer to plants or their behavior in terms implying reasoning faculties. Of course, plants are never reasoning things, reasonable as many of their actions appear to be, and to ascribe such qualities to them is to saddle them with attributes perfectly foreign to the plant world.

Source: Project Gutenberg royalty-free text

#### In contrast to supervised learning, unsupervised learning trains a machine with unlabeled data, such as the text of a book. Training an AI system with unlabeled data is more difficult because the system can’t make predictions until it has structured the data itself. In the book example, structuring the data would involve breaking down the text and finding relationships between words and sentences. So, algorithms explore the data and try to find structure.

##### For example, a system might be fed many articles about different kinds of plants and form its own conclusions of their attributes. When the system ingests new text describing a plant, it identifies it and gives it a confidence value.

#### Example

##### An AI system ingests data that is not labeled

##### Unsupervised learning and reinforcement learning require a system to develop its own structure either by analyzing large amounts of data (unsupervised learning) or by trial-and-error (reinforcement learning).

##### Katie has a huge amount of warehouse data to sort but doesn’t know how to categorize it.

### Reinforcement Learning

#### With reinforcement learning, a machine is not given specific information to ingest. Instead, it learns through trial and error. The machine’s algorithms are rewarded when it performs a correct action and penalized when it doesn’t.

##### Suppose this system is given a photo that probably depicts a dog, and it’s asked, “Is this a dog?” Remember, it has been fed little or no structured information about dogs.

##### The machine answers YES or NO, and gives itself a confidence value that is somewhere between 100% correct and 100Reinforcement learning% incorrect.

##### Then it is given new information indicating whether that answer really was right or wrong. This is where the reinforcement takes place.

###### For each answer that’s largely wrong, the machine is penalized: its algorithms are adjusted and the picture is sent back for another try.

###### But for each answer that’s largely correct, the algorithms are rewarded.

##### After these penalties and rewards happen many times, the machine’s answers become more accurate and its confidence value grows higher.

#### This is particularly useful when a machine needs to work on a specific type of problem. The machine continuously make decisions until it reaches a long-term goal. Each decision the machine makes is based on the previous decision. This is common in an area like game-playing, where a series of moves can win or lose a game.

#### Example

##### An AI system learns by trial and error

##### Unsupervised learning and reinforcement learning require a system to develop its own structure either by analyzing large amounts of data (unsupervised learning) or by trial-and-error (reinforcement learning).

##### Pedro is working with a chess-playing AI system. He rewards it when it wins and penalizes it when it loses.

##### Aditi is training an AI system in which it is penalized for answers that are largely wrong and rewarded for answers that are largely correct.

### How do Machines Learn?
 
two different technologies by which machine learning takes place:classical machine learning and members of a group of technologies called thedeep learning ecosystem.


## M2 Classical Machine Learning

### About this Module

Learning objectives



After completing this module, you should be able to:



- Describe decision trees, linear regression, and logistic regression
- List and explain advantages of classical machine learning
- Describe and explain how a sigmoid function is used in machine learning


### Classical Machine Learning

#### Classical machine learning began in the 1950s. AI systems learned by ingesting data and getting better at recognizing patterns. The AI systems could predict things like the distance between points or the intensity of values.
 
Like all machine learning, the classical form depends onalgorithms


##### Classical machine learning uses a small number of algorithms in a relatively simple arrangement.

##### Sometimes machine learning algorithms are binary, which means that they output one of only two values. Typical binary results might be a 1 or a 0, a YES or a NO, and a TRUE or a FALSE.

##### Other classical learning algorithms are more complicated. For example, their result might be represented as a position on a multidimensional graph rather than “this point” or “that point”. Here are three typical algorithms that are used in classical computing:

###### Decision tree

###### Linear regression

###### Logistic regression

### Decision Tree
 
Adecision tree is asupervised learning algorithm. It operates like a flowchart. You can think of a flowchart as an upside-down decision tree. The flowchart has aroot node (where the flowchart begins), branches that connect tointernal nodes, and more branches that connect toleaf nodes.


#### Example

##### What major should I take, based on professor's names and my level or interest?

###### Deciding a major would use a decision tree based on professors' names and personal interest.

### Linear Regression

#### Linear regression is another type of algorithm. It relates to data that might be graphed as a straight line.

##### For example, a business might believe that more advertising spending leads to better sales. This could be graphed as a series of dots that form a rising straight line, as depicted here.

#### Without adjustment, resulting graph is too general to help a business make a good decision. That’s where linear regression can help. Linear regression can learn all the variables, then calculate a reasonably accurate prediction of how advertising will impact sales at some time and location in the future. In effect, linear regression resolves the mass of dots into a “most likely” line that can be used for simple prediction.

#### A linear regression answers a question such as “If this increases by X, how much will Y increase?”

#### Example

##### How do advanced placement (AP) classes passed related to college acceptances?

###### More AP classes passed leading to more college acceptances would use linear regression.

##### What type of algorithm would help you ﬁnd out what you might earn for a salary if you have different levels of college degrees in computer science?

##### You’ve been asked to create a machine learning service that helps people choose what concert to attend on a particular date based on the type of music they prefer, who is singing, and where the event is taking place.

### Logistic Regression

#### In some situations, a relationship does not fall in a straight line. Sometimes a system uses values that require a specific, limited kind of outcome, such as something between 0 and 1 (or NO and YES).

#### In this situation, a graph can form what’s called a sigmoid function, or an S-shaped curve, as shown in the accompanying example. For any set of variables, the outcome (which is a point on the S-curve) falls between 0 and 1.

在这种情况下，图形可以形成所谓的 S 型函数，或称 S 形曲线，如示例所示。对于任何一组变量，结果（即 S 曲线上的一个点）都在 0 到 1 之间。


#### A logistic regression answers a question such as “If this increases by X, will the value of Y be closer to 0 or 1?”

#### Only logistic regressions have outputs between 0 and 1

#### Example

##### How do hours spent studying related to passing an exam?

###### An exam passed or failed is binary (YES or NO) so relating it to hours studied would use logistic regression.

##### You want to know how many hours to study to pass an exam. The “hours of studying” data forms a sigmoid function, or an S-shaped curve, between “fail” and “pass”.

### Classical ML is Not Obsolete

#### Classical machine learning can be outperformed, at some tasks, by newer methods that are part of the deep learning ecosystem.

#### But there are still reasons to use classical machine learning. These include:

##### Work with structured data

###### Classical machine learning is used mostly with structured data from databases, such as hours studied compared to grades earned.

##### Lower expense to operate

###### Classical machine learning requires less computing power than deep learning ecosystems. They can run on less expensive computers with less powerful processors, which lowers the price for smaller businesses, communities, or healthcare systems that share time on them in pay-as-you-go arrangements.

##### Easier to interpret

###### Deep networks are so complex that even AI researchers don’t entirely understand what’s going on inside. As a result, AI researchers are not always able to determine when deep network systems are producing invalid outputs. Compared to these mysteries, classical results can be easier to debug, and to test for accuracy and lack of bias.

## M3 The Deep Learning Ecosystem

Learning objectives



After completing this module, you should be able to:



- Describe how neural networks are inspired by the human brain
- Trace the flow of information through a perceptron’s nodes
- Describe machine learning’s trial-and-error learning process
- Define and describe deep learning and its ecosystem


### About this Module

#### demonstrate the concept of machine learning:

##### Determine the farthest distance from a target that an archer can reliably hit bullseyes by shooting arrows repeatedly while walking closer and closer to the target.

### Inspired by the Human Brain
 
Today, machine learning has evolved into a collection of powerful applications called thedeep learning ecosystem. The foundation for many applications is called aneural network. A neural network uses electronic circuitry inspired by the way neurons communicate in the human brain.


##### In the brain, cells called neurons have a cell body at one end where the nucleus resides, and a long axon leading to a set of branching terminals at the other end. Neurons communicate to each other by receiving signals into the axon, altering those signals, then transmitting them out through the terminals to other neurons. Researchers estimate that a human brain has about 100 billion neurons, each one connected to up to 10,000 other neurons.

在大脑中，神经元细胞的一端是细胞体，细胞核就位于此处；另一端是一条长长的轴突，通向一组分支末端。神经元通过轴突接收信号，改变这些信号，然后通过末端将其传输到其他神经元，从而实现相互交流。研究人员估计，人脑约有1000亿个神经元，每个神经元与多达1万个其他神经元相连。


###### Biological input
A signal passes from the terminal of one neuron into the axon of another, using a combination of electrical and chemical reactions.

###### Biological input and response
Signals enter the cell body, which computes a response that then emerges from the other end of the cell
 
In a neural network, a building block, called aperceptron, acts as the equivalent of a single neuron. A perceptron has aninput layer, one or morehidden layers, and anoutput layer. A signal enters the input layer and the hidden layers run algorithms on the signal. Then, the result is passed to the output layer.


在神经网络中，一个称为感知器的基本单元相当于一个神经元。感知器有一个输入层、一个或多个隐藏层和一个输出层。信号进入输入层，隐藏层对信号运行算法。然后，结果被传递到输出层。


###### Neural network input and response
Similar to the way a signal passes through and is altered by a neuron, a signal enters a perceptron’s input layer, then passes through and is altered by algorithms within nodes in the hidden layer. Then the response emerges from the hidden layer and is transmitted onward from the neuron’s output layer.

#### The hidden layers in a neural network resemble, as a group, the long cell body that connects dendrites to axons within a human brain cell. Those hidden layers contain nodes. Each node runs an algorithm and bits of additional code to test and adjust its result. When the value reaches a certain threshold, the node “fires”.

##### Note: A node often uses a sigmoid function to determine whether or not to “fire”. As explained previously, a sigmoid function can generate a binary answer, such as, YES or NO. The binary answer tells the node whether or not to fire. You can think of the threshold as a hurdle a solution must jump over to give a result of YES.

##### If there are other nodes connected to the node, they are activated when the signal reaches them. If the other nodes reach their own thresholds, then they fire. The signal cascades down through the hidden layers in a way that’s somewhat similar to how a signal passes down the body of a human brain cell.

#### Keep in mind that these resemblances are only similarities. Neural networks are inspired by the human brain, but the activities inside neural networks are quite different.
 
After calculating values, neural networks often assignWeightto those values that impact the final result


### A Path through a Neural Network

#### The operation of a neural network is pure mathematics. The network isn’t “thinking”; it is calculating. But it’s using those calculations to create an output that humans can interpret as an answer or a recommendation.

#### in a neural network, individual nodes in a layer work on algorithms simultaneously. The nodes not only calculate but also adjust themselves in response to external factors. This is machine learning.

### ML is Often Trial and Error

#### how does a neural network learns in the first place. The answer is: by continuously adjusting itself, in a process that humans refer to as trial and error.

#### Once a neural network has ingested or already learned a certain amount of data, it stores the data in its “body of information”, called its corpus.

一旦神经网络吸收或学习了一定量的数据，它就会将数据存储在其“信息体”中，即语料库。


##### In order to learn, the neural network constantly tests new data or the results of its calculation against its corpus.

##### If the network determines that the new data or results don’t match the patterns it has already established, it modifies those patterns for a better fit.

##### Sometimes, to improve a single match, the network tests hundreds or thousands of modifications very rapidly and makes adjustments.

##### Then, the network tests to determine if the match is improving. So, step by step, the machine learns.

#### ML makes many guesses

##### Machine learning uses its tremendous calculation speed to make many guesses that bring it closer and closer to an answer.

###### It randomly makes its first guess, sets that guess as a variable, then tests how accurately the guess fits with both old and new data. Next, it makes an adjustment to the variable and tries again. Using mathematical processes to help it choose right-size adjustments, the system keeps on trying, getting closer and closer to perfection but never quite reaching it.

##### For this reason, many AI systems output a confidence value along with an answer or prediction

###### For example, a system predicting effective treatments for a cancer patient might output two or three suggested approaches, along with a measure of how confident it is that each treatment might work. This reflects how the system reaches those decisions. The system also leaves the final decision to the doctor who knows the patient.

##### Any computer can perform at least a crude kind of machine learning based on cycles of estimation. Classical machine learning can do it, too. But depending on the complexity of a problem, a conventional computer or even a classical system might take days (or centuries!) to reach a conclusion.

任何计算机都能执行至少一种基于循环估算的粗略机器学习。经典机器学习也能做到。但根据问题的复杂性，传统计算机甚至经典系统可能需要数天（甚至数百年！）才能得出结论。


##### In many modern applications of AI, the unstructured data involved is complex enough to overwhelm even a simple perceptron, such as to decide whether to order pizza in a previous lesson. So, a perceptron requires more brainpower in the form of deep learning. Deep learning relies on multiple layers of nodes (even multiple groups of perceptrons with multiple layers of nodes!) to finish the work in reasonable time.

### From Perceptrons to Deep Learning

#### advanced AI systems use many hidden layers whose algorithms pass the results of sophisticated calculations. This is a deep neural network (DNN).

##### DNN layers can be arranged in groups or elaborate blocks of groups for greater power. DNNs can even be doubled in competing teams that judge and learn from each other’s mistakes, without human intervention. This creates powerful reinforcement learning.

#### What DNNs can do

##### Photo Identification

###### Technologists can use a DNN to examine an historic photo of unknown persons or places. The DNN compares what it finds with millions of pictures in its corpus and then outputs full names and possible locations.

##### Housing Construction

###### Real estate companies an use a DNN to predict changes in housing prices across an entire city or state. DNNs can help real estate companies predict business trends and determine how to invest in materials and labor.

##### Self-driving Cars

###### Automobile engineers can use DNNs to model millions of driving situations and help self-driving vehicles navigate safely.

##### Cancer Treatment

###### Radiologists can use DNNs to identify variations in MRI images that are otherwise invisible to the human eye. Radiologists can receive early warnings of potentially treatable cancers.
 
An internet search for deep neural network examples can reveal many additional ways that machine learning impacts your life.Many forms of DNN devices make up the modern deep learning ecosystem.


## M4 Generative AI

### About this Module

Learning objectives



After completing this module, you should be able to:



- Define generative AI
- Describe how generative AI works
- Identify some examples of generative AI applications
- Describe the impact of generative AI to businesses
- Identify some current limitations of generative AI


#### Generative artificial intelligence (AI) is a powerful and exciting type of AI that generates new, original content, such as images, music, videos, data, code, responses to questions, and a whole lot more. It’s a technology that is revolutionizing the way people live, work, and enjoy their leisure time.

### What is Generative AI?

#### Generative AI is a type of artificial intelligence that creates new, original content that people have never seen before

##### Most AI systems are discriminative AI models, which predict and classify data

大多数人工智能系统都是判别式人工智能模型，可以预测和分类数据

 
In contrast, generative AI models are a type ofdeep learning AI systemthat uses algorithms to generate content based on a submitted prompt, thus the name of generative AI


#### For example, a discriminative model could tell a bicycle from a truck and a generative model could generate a new image that looks like a bicycle.

#### So, generative AI’s distinction from other AI systems is its ability to produce content that is new and considered creative, such as images, videos, music, synthetic data, essays, answers to questions, and more.

#### Generative AI’s output has gained global attention due to the uniqueness, high quality, and speed of content generation. Generative AI is a revolutionary change that’s as radical to global humanity as the invention of electricity and automobiles. Let’s see how generative AI works.

### How does Generative AI Work?

#### Think of generative AI as a virtual artist. Just like a human artist, it needs inspiration and tools to create something unique. Instead of using paint and canvas, however, generative AI uses algorithms and data sets.

#### Overall Generative AI Process

##### 1. First, a person feeds the AI a large amount of data. This could be anything from images and sounds to text and numbers.

##### 2. Then, the AI analyzes this data, looking for patterns and relationships between the different pieces of information. The neural network is trained on a dataset of examples of the type of output it is intended to generate, such as images or text. During the training process, the neural network learns to identify patterns and relationships in the input data and use them to generate new outputs that are similar to, but not identical to, the examples it was trained on.

##### 3. Next, the AI uses what it has learned to create something new. The neural network generates new outputs by inputting a random seed value. The seed value serves as the starting point for the generation process. The neural network processes the seed value and generates a new output that is based on the patterns and relationships it learned during training.

###### For example, if someone gave the AI a set of images of dogs, it might use its knowledge of different dog breeds to create an image of a new dog that doesn't exist in real life.

#### Generative AI can also complete more complex tasks, like writing stories or composing music. In these cases, the AI analyzes patterns in language or music to create something entirely new.

#### Types of generative AI models

##### Variational AutoEncoder (VAE)

###### Think of variational autoencoder (VAE) models as a skilled artist who can look at a painting, quickly sketch a simplified version of it, and then recreate a new painting using only that simplified sketch as a reference. The artist is capturing the essential elements of the painting and then using them to create a new work of art.

###### VAEs use a similar process. The "encoder" network compresses the input data into a lower-dimensional representation and the "decoder" network reconstructs the original data from this compressed representation. This allows VAEs to capture the underlying structure and patterns in the data, which can then generate new, similar data.

##### Generative Adversarial Network (GAN)

###### Think of a generative adversarial network (GAN) model as a competition between a skilled forger (the generator) and a talented art critic (the discriminator). The forger creates fake paintings, while the critic tries to determine whether each painting is genuine or a forgery. As the forger improves their technique, the critic becomes more discerning, and this cycle continues until the forger can create near-perfect forgeries.

###### In GANs, the generator creates new data, while the discriminator evaluates the quality of the generated data. The generator tries to create data that is realistic enough to fool the discriminator, while the discriminator learns to better distinguish between real and generated data. This competition leads to the generator creating increasingly realistic content.

##### AutoRegressive

###### Imagine an autoregressive model as a skilled storyteller who listens to the beginning of a story and then continues it by predicting what comes next based on the words and events that have occurred so far. The storyteller uses their knowledge of language, grammar, and storytelling conventions to create a coherent and engaging continuation of the story.

###### Autoregressive models generate new content by predicting the next element in a sequence based on the previous elements. They are particularly well-suited for generating text because they can model the conditional probabilities of words and characters in a sentence.

### Examples of Generative AI Applications

#### ChatGPT

##### OpenAI launched ChatGPT, an AI chatbot, in November 2022. Able to interact by using conversational natural language, this AI tool goes beyond the traditional search engine responses of simply listing related results. Instead, ChatGPT follows instructions given in the prompt and provides a detailed response. For example, with ChatGPT, a person can enter a text prompt of “Write a poem about cats” and the result will be a poem about cats, rather than a listing of websites about cats.

#### IBM Watson Discovery

##### IBM Watson Discovery uses foundational technologies, such as large language models (LLMs), to obtain insights from what it is that we don’t know that we don’t know. It’s used widely in genomic research discovering what amino acids might lurk inside the protein not known before and unearth the relationship of various actors or entities for government security related questions.

#### Dall-E and Dall-E 2

##### Developed by OpenAI, these are generative AI models that use natural language text input to generate digital images. The first version of DALL-E could only render AI-created images in a cartoonish fashion, but the latest version can produce much more realistic images due to improved image processing algorithms.

#### BARD

##### Bard is a generative AI tool that Google launched in an initial, limited capacity in March 2023. Bard is founded on Google’s Bidirectional Encoder Representations from Transformers (BERT) model. It isn’t generative AI; rather, Google developed it for natural language processing (NLP), especially for its capacity to interpret the nuances of a user’s search words. Bard builds on BERT’s capability of natural language interactions with Bard’s generative AI capability to generate new content. For example, musicians can use Bard to compose music and lyrics.

### Industry Uses of Generative AI

#### Sports

In sports, generative AI can help improve athletic performance and enhance fan engagement.



One application of generative AI in sports is the creation of personalized workout plans. By analyzing an athlete's biometric data, generative AI can create customized workout plans tailored to the athlete's fitness level and goals. This technology can improve athletic performance by providing athletes with targeted and efficient training regimes.



Another application of generative AI in sports, around fan engagement, is the creation of realistic 3D models of athletes for use in sports video games and virtual reality experiences. By using generative AI, game developers can create highly realistic and personalized virtual athletes that can interact with users in real-time. This technology can enhance fan engagement by providing users with immersive and engaging sports experiences.



Generative AI can analyze sports data and identify patterns and trends that can inform coaching strategies and player selection.



Overall, generative AI has the potential to transform the way people play, coach, and experience sports, enabling new levels of personalization, efficiency, and engagement.



Use case



The Miami Dolphins, an American football team in the United States, are using generative AI to improve player performance and prevent injury. They are collaborating with a company called Blue River Technology to develop a computer vision system that uses generative AI to analyze video footage of players and identify areas for improvement. The system analyzes players' body movements and identifies areas where they could be at risk for injury. By using generative AI in this way, the Miami Dolphins can identify potential issues before they become serious problems, enabling them to take proactive measures to prevent injuries and improve player performance.



This technology has the potential to transform the way that sports teams approach player health and performance, improving the overall quality of play and reducing the risk of injury for athletes.


#### Entertainment

In the entertainment industry, generative AI can help create new and immersive experiences for users.



One application of generative AI in entertainment is the creation of a wide variety of highly realistic and personalized virtual characters and environments for video games and virtual reality experiences. For example, generative AI can create realistic facial expressions and body movements for virtual characters, enhancing the user experience and immersion.



Another application of generative AI in entertainment is the generation of personalized music playlists. By analyzing a user's listening history and preferences, generative AI can create unique and personalized music playlists that cater to each individual user's tastes.



This technology can enhance the user experience by creating highly personalized and engaging music experiences.



Use case



Amper Music uses generative AI to create original music for video games, films, and other multimedia projects. Their platform allows users to input parameters such as mood, genre, and tempo, and then generates a unique and original piece of music in real-time. It generates music using a generative model that is trained on a large dataset of musical patterns and structures. By using generative AI to create music, Amper Music can offer highly customizable and original compositions tailored to each individual project's needs.



This technology has the potential to transform the creation of music for multimedia projects, enabling more efficient and personalized music production.


#### Healthcare

In healthcare, generative AI can help improve disease diagnosis, medical imaging, and personalized medicine.



One application of generative AI is in the generation of synthetic medical images, which can train machine learning algorithms and improve disease diagnosis. For example, generative AI can generate synthetic medical images of rare diseases, which can be difficult to obtain in real life.



Another application of generative AI in healthcare is the creation of medical simulations. These simulations can help train healthcare professionals and reduce medical errors. By generating synthetic patient data, generative AI can also train predictive models and improve personalized medicine.



Generative AI has the potential to transform healthcare by enabling the creation of realistic medical simulations, improving disease diagnosis, and enhancing personalized medicine.



Use case



PathAI uses generative AI to improve the accuracy of disease diagnosis through the analysis of medical images. Specifically, PathAI has developed a deep learning algorithm that can accurately detect cancer cells in digital pathology images. This algorithm was trained on a large dataset of annotated pathology images using a variational autoencoder (VAE) generative model. The VAE learned the underlying structure of the pathology images to generate synthetic images that were like the real images in the training set. By training their algorithm on both real and synthetic images, PathAI was able to improve the accuracy of their cancer detection algorithm.



This technology has the potential to improve the accuracy and speed of cancer diagnosis, to ultimately improve patient outcomes.


#### Business

In business, generative AI can help improve decision-making, personalize customer experiences, and enhance operational efficiency.



One application of generative AI in business is the generation of synthetic data. By generating synthetic data, companies can augment their existing datasets and improve the accuracy of predictive models. For example, a financial institution could generate synthetic financial data to train their predictive models and improve risk management.



Another application of generative AI in business is the creation of personalized product recommendations. By analyzing a customer's purchase history and preferences, generative AI can create personalized product recommendations tailored to each individual customer. This technology can improve customer satisfaction and increase sales.



People are also using generative AI to improve operational efficiency by creating synthetic data for testing and validation.



Generative AI has the potential to transform the way businesses operate by improving decision-making, enhancing customer experiences, and increasing efficiency.



Use case



Syntiant uses generative AI to develop low-power, high-performance deep learning chips for a range of industries, including smart home devices, wearables, and voice-controlled devices. Their deep learning chips are designed to process data on the device itself, rather than relying on cloud-based processing, which can reduce latency and improve privacy. To train their deep learning models, Syntiant uses a generative adversarial network (GAN) to create synthetic data by generating new data samples that are similar to the training data. By training their models on both real and synthetic data, Syntiant was able to improve the accuracy of their deep learning chips, making them more reliable and efficient.



This technology has the potential to transform the way that companies design and manufacture deep learning chips, enabling a new generation of low-power, high-performance devices.


### Limitations of Generative AI

#### Lack of originality: Generative AI models rely on large datasets to learn and generate content. As a result, they might not create entirely original content but rather mimic patterns from their training data, which can lead to a lack of creativity and innovation.

#### Incompleteness: While generative AI models are becoming increasingly sophisticated, they still struggle to understand the nuanced contexts and might generate incomplete or nonsensical content.

#### Bias: Generative AI models can perpetuate existing biases present in their training data, leading to the generation of biased content that might reinforce stereotypes and discriminatory behavior.

#### Computational resources: Training and deploying generative AI models require significant computational power, which can be expensive and contribute to environmental concerns such as energy consumption and carbon emissions.

### Ethical Concerns of Generative AI

#### Misinformation and fake content: Generative AI can create convincing fake content, like deepfakes or falsified news articles, which can lead to the spread of misinformation and have severe consequences for individuals and societies.

#### Intellectual property and copyright: Generative AI can produce content that resembles copyrighted material. This raises questions about intellectual property rights and potential infringements.

#### Privacy: Generative AI can create realistic images and text about individuals, potentially violating their privacy and causing harm to their reputation.

#### Loss of human touch: As generative AI becomes more prevalent, there is a risk that the human touch will be lost in various creative domains, potentially leading to a decline in the appreciation of human-created art and culture.

#### Unemployment and job displacement: The rise of generative AI might lead to job displacement in creative industries, as machines take over tasks previously performed by humans.

### Expand for some more thoughts

#### Generative AI is a tool that is readily available to everyone. So, consider this as a change in thinking that is occurring.

#### As students use generative AI, they will need to consider the limitations. For example, students will need to review the generated content to assess if there are any biases, errors, omissions, misinformation, or a lack of originality. And then the student will need to take corrective actions to address those issues.

#### In addition, instructors know that generative AI is easily available and powerful, so class assignments might change from asking students to write an essay to asking them to assess the essay that generative AI created and report on the embedded limitations, their related implications, and provide solutions to them.

## M5 Future AI Trends

### Where does AI go from here?

#### You live in the second level of AI, called Broad AI, in which machine learning systems have begun to appear in your everyday life. Broad AI can’t think abstractly, strategize, or use previous experience to come up with new, creative ideas.

#### But data scientists and programmers are already working on the third level, called General AI. The goal of General AI is to create systems that can perform any intellectual task that a human being can—and more. Some scientists believe that this goal may be reached in about twenty years (the early 2040s).

### What's in Store for the Future?

#### AI Everywhere

Soon, AI will support seamless connections across industries, ranging from finance, to education, to healthcare. AI will help people work more productively and create new career opportunities.



Industries:



- Healthcare
- Finance
- Agriculture
- Government
- Education
- Energy
- Science
- Business solutions


#### Deeper Insights

New technologies will be able to sense and analyze things at a level of understanding that was never before possible. This includes future-forward technologies with unfamiliar names, like quantum computing. Quantum computing is a dramatically different way to calculate, based on the behavior of subatomic particles.



Technologies:



- Quantum computing
- Distributed deep learning
- Neuromorphic systems
- Homomorphic encryption
- Machine foresight
- Cognitive discovery


#### Engagement Reimagined

New forms of human-machine communication, based on blockchain, conversational bots, and more ideas, will transform how you interact not only with your friends, family members, and coworkers, but also with machines that listen and engage in complex conversations.



Interactions:



- Human-machine collaboration
- New AI modalities
- Augmented reality
- Global trade logistics
- Blockchain for payments


#### Personalization at Scale

Machines will interact with you in ways tailored to your particular desires, habits, and level of comfort. Today, websites already offer merchandise based on orders you’ve made in the past. Soon, you’ll use sites that recognize you and know and understand the things you love. This includes the fashions you follow. Future sites will discuss your fashion preferences with you and offer them perfectly fitted to your size and needs.



Ways to personalize:



- Personalized healthcare
- Micro-segmentation
- Personalized finance
- Targeted marketing
- Personalized learning
- Individualized solutions


#### Instrumented Planet

Billions of sensors generating exabytes of data every day will improve the safety, sustainability, and security of our planet. You won’t get caught in a surprise storm. You will enjoy food from crops grown in new ways that provide maximum taste and nutrition, with minimum damage to the environment.



Connections:



- Environmental solutions
- Digital agriculture
- Connected cars
- Geospatial temporal data and analytics
- Smart sensors


### What about your Future?

## Summary

### 1. Using advanced mathematics, machines can learn either in classical ways or with neural networks.

### 2. Machines can learn from structured or unstructured data and teach themselves through trial-and-error.

### 3. Machine learning tools include logic methods, such as decision trees, linear regression, and logistic regression.

### 4. Neural networks, inspired by the human brain, build perceptrons with layers of algorithm nodes to perform complex calculations.

### 5. Multiple groups of multilayer perceptrons, arranged in different ways, extend machine learning in the deep learning ecosystem.

### 6. Today, people carry on simple conversations with machine learning AI systems using what is known as Broad AI.

### 7. Generative AI has gained attention worldwide as a revolutionary change for creating new and unique content.

### 8. In the future, General AI systems will perform unprecedented levels of analysis to help humans improve life on a global scale.

# 4. Run AI Models with IBM Watson Studio

What you’ll learn



After completing this course, you should be able to:



- Describe machine learning algorithms and models
- Explain the purpose of IBM Watson Studio
- Describe the key features and benefits of IBM Watson Studio
- Set up a machine learning project in IBM Watson Studio
- Create a Cloud Object Storage resource
- Import a data set into IBM Watson Studio
- Build an AI model using AutoAI in IBM Watson Studio
- Run a prediction experiment for an AI model
- Explain the confusion matrix
- Save a model as a Jupyter Notebook
- Download a notebook in Jupyter Notebook (.ipynb) format


## M1 Intro IBM Watson Studio

### About this Module

#### Describe machine learning algorithms and models

#### Explain the purpose of IBM Watson Studio

#### Describe the key features and benefits of IBM Watson Studio

### ML Models
 
Machine learning is, in the end, about making predictions using statistics and calculus; both of which are used in bits of code calledmachine learning algorithms. These bits of code, in turn, can be organized in large-scale computer programs calledmachine learning models.

 
A machine learning algorithm is a set of program code.

If you’ve ever worked with code, you might know what afunction is. A function is a set of logical operations that inputs some sort of data, analyzes or transforms it, and then outputs a result. But in a machine learning algorithm, that analysis often hasa specific goal: to recognize patterns in data sets.


###### For example, an algorithm in an AI weather prediction system might ingest a series of sunlight measurements and water temperatures, then analyze and output a pattern describing how these factors appear to influence each other.
 
A machine learning model is a group of machine learning algorithms.

Operating together, they detect patterns among their algorithms’ output and use those patterns to make predictions.


###### For example, a model whose algorithms look at patterns regarding temperature, climate, geography, and so on might predict a rainy-day next Saturday.

#### How is this different from the way conventional computer programs operate?

##### A machine learning model doesn’t depend only on a human to write its code or to adjust its programming if its predictions aren’t right.
 
Instead,a machine learning model can reprogram itself. So if, for example, a weather model tends to get a certain type of prediction wrong, it can adjust its algorithms (weights and biases, statistical constructs) to improve the accuracy of its predictions.


### Early Model Development Problems

#### Watson Studio was born from a need

### The IBM Watson Studio Solution

#### IBM’s Watson Studio solution is what researchers call an integrated development environment (IDE). Named after IBM’s founder, it pulls together the most useful development and analytic tools, wrapping them in a development platform that is powerful enough to meet large-scale challenges, yet simple enough that developers can master it quickly.

### Integrated Development Environment

#### Watson Studio gives developers:

A collaborative data science and machine learning environment
Easy visualizations with drag-and-drop code
An efficient workflow
A built-in neural network modeler
Open-source tools such as Jupyter Notebooks and RStudio

### Typical Tools and Dashboards

#### Automated data preparation

##### IBM Watson Studio has a feature called AutoAI that prepares raw data for machine learning. It can apply various algorithms to clean and structure the data, automatically select an appropriate model, and optimize its output for the fastest, most useful output.

#### Visual neural network design

##### Watson Studio helps developers create machine learning flows and design neural networks visually, using a simple drag-and-drop interface and open source code libraries.

#### Sophisticated analysis and prediction

##### Watson Studio recommends algorithms and uses the latest neural networks to predict and build patterns. It helps programmers create visualizations simply by selecting data items, after which the system itself can choose the best way to visualize its findings.

#### Unified dashboard displays

##### Watson Studio dashboards not only visualize the results of complex analyses, they also gather related views on data into a single place where clients can find and understand the information they seek. These dashboards don’t require specialized coding or database skills, and researchers can easily share them across the internet.

#### Watson Feature

##### Learn

###### Hundreds of built-in tutorials

###### Detailed reference materials

###### Free Notebook and Model examples

##### Create

###### Drag-and-drop interface

###### Visual modeling tools for neural network design

###### Compatibility with Open Source code

##### Collaborate

###### AIO Dev Environment

###### Social communication features

###### Easy commenting and project tracking

### Putting Watson Studio models to work

#### With IBM Watson Studio, a modest-size team of specialists could build a machine learning model that will, as time goes by, get better and better at spotting major trends in sneaker design. It could even follow celebrity fashions, then begin predicting new trends more and more effectively.

## M2 Prepare Your ML Project

### About this Module

### Your AI ML Project

### Simulation: Start your project and upload data

## M3 Conduct Your ML Project

### About this Module

### Simulation: Configure and Run your project

### Understand the Confusion Matrix

## M4 Save your AI Model

### About this Module

### Simulation: Save your model as a Jupyter notebook

### You've done a great job!

## Summary

IBM Watson Studio is an integrated development environment (IDE).



It was developed to solve problems that development teams experienced in communication and project coordination.



It has the capacity to construct, provision, run, and test machine learning models.



It can save its results as working models or as editable notebooks.



You had the opportunity to practice in simulations of IBM Watson Studio to:



- Provision the Watson Studio service
- Set up a new AI machine learning project
- Import bank loan risk data
- Create four machine learning models
- Train these models
- Run them competitively
- Identify the model that most effectively predicted bank loan risk



You considered a client’s business need, then created and tested an AI solution that could meet that need.


# 5. AI Ethics

## M1 What is AI Ethics?

### About this module

#### Every day people interact with AI systems, but how much do they trust them? This module briefly explains the five pillars of AI ethics and how each is important in building AI models and systems that can be trusted.

### The age of AI

#### Artificial intelligence is everywhere.

##### AI can make life easier and safer by helping people make more informed decisions, connecting them with the right information they need at the right time, and finding patterns or efficiencies that they might not otherwise know about.

#### But AI also has the potential to do harm.

##### For example, AI can be used when determining who gets a loan, who gets accepted to college or selected for a job, how employees are compensated, or even the lengths of prison sentences.

### Can AI be trusted?

#### As AI is increasingly embedded in everyday life, it is vital that people can trust AI. Practitioners infuse trust into AI systems with AI ethics. AI ethics is a multidisciplinary field that investigates how to optimize AI’s beneficial impact while reducing unintended or adverse outcomes. There are five pillars of AI ethics: fairness, robustness, explainability, transparency, and privacy. These pillars are focus areas that help make AI trustworthy.

#### AI is a part of our lives, and its influence is growing, so it is crucial that people who design, develop, deploy, procure, and use AI understand how to use AI ethics to minimize harm and optimize benefits.

### AI Ethics is a multidisciplinary field that investigates how to optimize AI’s beneficial impact while reducing unintended or adverse outcomes.

### In the context of AI, harm doesn’t necessarily have to do with physical harm. The harm can be less obvious, taking the form of inequity, discrimination, or exclusion. And this harm can be subtle because people may not always know when they are interacting with AI or when and how AI may be influencing decisions about them.

## M2 What is Fairness?

### About this module

#### An AI model is systematically giving an advantage or disadvantage to a certain group.

#### In AI, fairness is the equitable treatment of individuals or groups of individuals.

#### Fairness is achieved when unwanted bias is mitigated. In AI, bias is a systematic error that has been designed, intentionally or not, in a way that might generate unfair decisions. Bias can be present in the AI system, in the data used to train and test the system, or even in both. Bias can emerge in an AI system because of cultural expectations, technical limitations, or unanticipated deployment contexts.

#### Fairness in AI aims to minimize unwanted bias

#### Unwanted bias is a systematic error in AI systems that may result in unfair outcomes.

### Meet the Team

### Identify the Issue

### Explain the Issue

#### Bias, in general, is a systematic error, but in the context of fairness, the concern is around unwanted bias. Unwanted bias places some groups or individuals at a systematic advantage and other groups or individuals at a systematic disadvantage
 
Unwanted bias places

privilegedgroups at a systematic advantage

and

unprivilegedgroups at a systematic disadvantage.


不必要的偏见使

特权群体处于系统性优势，

而

弱势群体则处于系统性劣势。


#### The reason to use groups is simple: to mitigate disparity in the outcome across the groups. In other words, to have an equitable outcome across the groups.

使用分组的原因很简单：为了减少不同组之间结果的差异。换句话说，就是为了在各个组之间实现公平的结果。


##### We divide the population into groups based on one or more attributes in the data that could introduce disparity or inequity in the outcome. The attribute that separates the population into groups is called a protected attribute. Some generally used protected attributes are race, age, sex at birth, gender identity, and ethnicity. But…there isn’t a defined set of protected attributes.

##### Note: For legal and other policy reasons, it is often the case that protected attributes are not maintained in the data set. In these cases, the team might impute them (which is fraught with its own biases) or might use the statistics from demographic data sets using a so-called transfer learning approach.

### Address the Issue

#### The team has identified the issue as one of fairness in the AI model. To achieve fairness, unwanted bias needs to be reduced. In AI, bias is a systematic error that, intentionally or not, can influence an AI system in a way that might generate unfair decisions. Bias can be present both in the AI system and in the data used to train and test it. Based on the data that was given to the AI system, bias had crept in and was affecting the system’s results.

#### For question 1: Is there a step to analyze the intended and unintended consequences of the application using a design-thinking approach? Do you think that such a step is necessary?

##### Yes, it is very important to understand known and hidden effects of the applications to mitigate significant harm. One way to try to better understand known and hidden effects is by considering layers of effect.  When you consider layers of effect, you think about the application’s primary effect (its intended impact), its secondary effects (known or predictable unintended impacts), and its tertiary effects (potential unpredictable or unforeseen unintended impacts). Considering layers of effect with a diverse and inclusive team helps identify a wider range of potential impacts, including potential harm.

#### For question 2: Which attribute in this story’s data set has the potential to introduce unwanted bias?

##### The "Employee education" attribute

#### For question 3: Is there a way to mitigate bias at every stage of the AI lifecycle (from development to deployment)? How would you do it?

##### Yes, there are many ways to mitigate bias throughout the AI lifecycle. Throughout the AI lifecycle, it is critical to work with a diverse and inclusive team whose collective wisdom will help better identify potential bias issues. An AI models extract key patterns by looking at training data in order to make decisions and predictions. So, selecting high-quality data that is relevant, accurate, complete, and representative is important because using high-quality data will help reduce bias issues later in the lifecycle. Once an AI model goes to production, using tools to continuously detect, measure, and mitigate bias is also very important because it enables you to identify, understand, and remediate issues proactively and on an ongoing basis.

#### For question 4: What are the ways observed bias can be dealt with?

##### There are many ways to mitigate observed bias. The first step is to investigate where and why the model is exhibiting unwanted bias. Then, you can review the data and data labeling and fix any observed issues. You can also check to see if model retraining is needed.

## M3 What is Robustness?

### About this module

#### AI model withstanding intentional and unintentional interference

#### AI is increasingly used to help make crucial decisions, so it is vital that AI is secure and robust. When AI is robust, it can more effectively handle exceptional conditions, like abnormalities in input or malicious attacks, without causing unintentional harm.

### Meet the Team

#### Adversarial robustness refers to an AI model’s ability to resist being fooled.

### Identify the Issue

### Explain the Issue

#### Adversarial attacks are intentionally carried out on AI systems to accomplish a malicious end goal by taking advantage of AI system vulnerabilities.

#### An adversarial attack aims to negatively impact the system performance, exploit data used, and corrupt the model logic. The one who takes advantage of the AI system vulnerabilities to accomplish their motive is called an adversary.

对抗性攻击旨在对系统性能造成负面影响、利用所用数据并破坏模型逻辑。利用人工智能系统漏洞来实现其目的的人被称为对手。


#### the adversary attacks the system by adding small changes called perturbations or noise to the input image. The perturbation can be minimal and imperceptible to human eyes. However, when sent to the deployed AI model, the modified image results in an undesirable or incorrect prediction

#### Adversary Goals

##### Get access to personal information

###### Get access to patient’s personal information like age, gender, race, medical history, identification information, and finance information.

##### Make system learn the data that is in favor of the adversary

###### Add malicious x-ray samples to the input training data and make the system learn from the malicious data that is in favor of the adversary.

##### Force consistent misclassification of the input samples

###### Predict the presence of disease among significant numbers of patients who don’t have the disease or vice-versa. This also reduces the system performance.

##### Make the system predict a specific outcome.

###### Intentionally add noise to the data so more patients will fall under the “Disease Detected” category.

##### Steal or recreate the AI model

###### Learn the company’s AI model and related data. Develop a similar model and use for own purpose.

##### Recreate training data used for developing the AI model

###### Send malicious and corrupted x-ray images to the company’s AI application and recreate training data based on the system’s response.

#### There are multiple ways for an adversary to achieve the goals mentioned above including the following:

##### Getting access to the training data and learning the data distribution

##### Having permission to modify the data used for training and testing the AI system

##### Having access to the model code and parameters

##### Corrupting the user’s data and sending the modified data to the deployed AI system

#### The adversary might not necessarily experiment with only one way to enter a system. Instead, it is likely that the adversary might use a combination of different ways to attack a system. Also, the ways adversaries attack can vary from attack to attack.

#### Given the goals and needs, adversarial attacks can occur either at the model training or after the model deployment

### Address the Issue

## M4 What is Explainability?

### About this module

#### AI is exemplified by anyone being able to describe how an AI system makes a prediction or recommendation

### Meet the Team

### Identify the Issue

### Explain the Issue

### Address the Issue

## M5 What is Transparency?

### About this module

#### A trustworthy AI model should allow key facts about that model to be seen very quickly, just like the nutritional label on a box of food.

### Meet the Team

### Identify the Issue

### Explain the Issue

### Address the Issue

## M6 What is Privacy?

### About this module

### Meet the Team

### Identify the Issue

### Explain the Issue

### Address the Issue

## Summary

# 6. Your Future in AI: The Job Landscape
