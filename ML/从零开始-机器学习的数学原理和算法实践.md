 从零开始-机器学习的数学原理和算法实践

# Part 1: 补基础

## 1. 补基础：微积分

### 1.1 导数

#### 导数典型的应用场景就是对瞬时速度的求解
 (see:求解变速运动的瞬时速度)
#### 导数描述了自变量的微小变化导致因变量微小变化的关系

#### 复合函数求导

##### 加法法则

###### 基本函数相加形成的复合函数导数等于基本函数导数之和

##### 乘法法则

###### 基本函数相乘形成的复合函数导数等于“前导后不导加上后导前不导）

##### 链式法则

###### 基本函数嵌套形成的复合函数等于”外层导数与内层导数依次相乘

### 1.2 多元函数

#### 多元函数偏导数的求解方法就是对一个变量求导时，将其他变量暂时看成固定的参数

#### 梯度时导数对多元函数的推广，是多元函数对各个自变量求偏导形成的向量

##### 梯度就是多变量微分的一般化

##### 梯度的本意是一个向量，表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）

##### 一般来说，梯度可以定义为一个函数的全部偏导数构成的向量
 (see:6. 凸优化核心问题：梯度下降过程)
### 1.3 微积分

#### 微分

##### 求解变速运动的瞬时速度

###### 通过引入极限的概念，将瞬时速度定义为平均速度再Δt趋近于0时的极限值

##### 求解曲线上某点处的切线

##### 求解函数的最大值和最小值

#### 积分

##### 求解曲线的长度、曲面的面积、物体的体积

### 1.4 泰勒公式

## 2. 补基础：线性代数

## 3. 补基础：概率统计

# Part 2: ML的全景与关键

## 4. 全景图：机器学习路线图

## 5. 数据降维：主成分分析PCA

## 6. 凸优化核心问题：梯度下降过程

# Part 3: 算法与代码

## 7. 搞懂算法：线性回归

## 8. 搞懂算法：逻辑回归

## 9. 搞懂算法：决策树

## 10. 搞懂算法：支持向量机

## 11. 搞懂算法：聚类

## 12. 搞懂算法：朴素贝叶斯

## 13. 搞懂算法：神经网络

## 14. 综合实践：模型优化
